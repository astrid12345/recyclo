{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwJ2mXuWkxUr"
   },
   "source": [
    "This is a bare-bones file that demonstrates downloading a dataset from google drive and using it to train a YOLOv11 model.\n",
    "\n",
    "Consider this a placeholder only - if you're training a model for real, please overhaul this file however you deem necessary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 72526,
     "status": "ok",
     "timestamp": 1751014515933,
     "user": {
      "displayName": "Daniel Chin",
      "userId": "09517285653887583810"
     },
     "user_tz": -120
    },
    "id": "eenbcsguRgOT",
    "outputId": "5c30f708-e200-4814-b7ce-6451c5221c94"
   },
   "outputs": [],
   "source": [
    "!pip install -U ultralytics gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GbLG6fmSZJ1"
   },
   "outputs": [],
   "source": [
    "google_drive_file_id = '1N__ZI4KcmXmDADv4dYsKhIIZoe5-4iZg'  # <-- From sharing link in google drive, eg https://drive.google.com/file/d/1N__ZI4KcmXmDADv4dYsKhIIZoe5-4iZg/view?usp=sharing\n",
    "google_drive_file_name = '20250623_merged_yolo_reshuffled.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34088,
     "status": "ok",
     "timestamp": 1751014550076,
     "user": {
      "displayName": "Daniel Chin",
      "userId": "09517285653887583810"
     },
     "user_tz": -120
    },
    "id": "myyJ41lbRmQJ",
    "outputId": "96949145-8e60-4477-be9d-1a1088dc9757"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "import gdown\n",
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "\n",
    "project_root = Path('/content')\n",
    "dataset_root_name = 'yolo_dataset'\n",
    "output_path = project_root / google_drive_file_name\n",
    "extract_dir = project_root / dataset_root_name\n",
    "dataset_root_path = Path('/content') / dataset_root_name\n",
    "yaml_path = dataset_root_path / 'data.yaml'\n",
    "\n",
    "# Download from Google Drive and extract\n",
    "gdown.download(id=google_drive_file_id, output=str(output_path), quiet=False)\n",
    "print(f\"Dataset downloaded from google drive: {output_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12878,
     "status": "ok",
     "timestamp": 1751014562968,
     "user": {
      "displayName": "Daniel Chin",
      "userId": "09517285653887583810"
     },
     "user_tz": -120
    },
    "id": "Eb4Wf3TIo9zS",
    "outputId": "38cff305-1e48-44a5-f9a7-a93034d5a6b1"
   },
   "outputs": [],
   "source": [
    "# Extract files\n",
    "print(\"Extracting...\\n\")\n",
    "with zipfile.ZipFile(output_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "print(f\"Dataset extracted to: {extract_dir}\\n\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1751014562989,
     "user": {
      "displayName": "Daniel Chin",
      "userId": "09517285653887583810"
     },
     "user_tz": -120
    },
    "id": "TmnGcB7wlRTh",
    "outputId": "ad015550-1932-4df1-9b98-645c6db5e564"
   },
   "outputs": [],
   "source": [
    "# Update path in data.yaml to work with where we've unzipped it\n",
    "print(\"Updating data.yaml path...\\n\")\n",
    "with yaml_path.open('r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "data['path'] = str(dataset_root_path)\n",
    "data['train'] = str(dataset_root_path / 'images' / 'train')\n",
    "data['val'] = str(dataset_root_path / 'images' / 'val')\n",
    "data['test'] = str(dataset_root_path / 'images' / 'test')\n",
    "\n",
    "with yaml_path.open('w') as file:\n",
    "    yaml.dump(data, file)\n",
    "\n",
    "print(f\"Updated path in data.yaml to: {data['path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1751014563869,
     "user": {
      "displayName": "Daniel Chin",
      "userId": "09517285653887583810"
     },
     "user_tz": -120
    },
    "id": "t3uW76Smp_kK",
    "outputId": "3ec705e2-3487-4ab4-f2f0-e3050707c7dd"
   },
   "outputs": [],
   "source": [
    "# Convert_class0_to_80.py\n",
    "import os\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "LABELS_DIR = \"/content/yolo_dataset/labels\"  # Change this to your labels directory\n",
    "\n",
    "def convert_labels(root_dir):\n",
    "    updated_files = 0\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for file in filenames:\n",
    "            if file.endswith(\".txt\"):\n",
    "                file_path = os.path.join(dirpath, file)\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    lines = f.readlines()\n",
    "\n",
    "                new_lines = []\n",
    "                modified = False\n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    if parts and parts[0] == \"0\":\n",
    "                        parts[0] = \"80\"\n",
    "                        modified = True\n",
    "                    new_lines.append(\" \".join(parts) + \"\\n\")\n",
    "\n",
    "                if modified:\n",
    "                    with open(file_path, \"w\") as f:\n",
    "                        f.writelines(new_lines)\n",
    "                    updated_files += 1\n",
    "\n",
    "    print(f\"[âœ”] Updated {updated_files} files with class ID 80.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    convert_labels(LABELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 208370,
     "status": "ok",
     "timestamp": 1750848938473,
     "user": {
      "displayName": "Daniel Chin",
      "userId": "09517285653887583810"
     },
     "user_tz": -120
    },
    "id": "SQNWMAmYsEjn",
    "outputId": "391c940b-09c0-4112-e43b-2cc26e4e7a62"
   },
   "outputs": [],
   "source": [
    "# Sanity check that it's possible to train a model with the dataset\n",
    "dataset_yaml = Path('/content/yolo_dataset/data.yaml')\n",
    "model = YOLO('yolo11n.pt')\n",
    "results = model.train(data=str(dataset_yaml), epochs=1, imgsz=640, batch=16, freeze=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 103,
     "status": "ok",
     "timestamp": 1751014563985,
     "user": {
      "displayName": "Daniel Chin",
      "userId": "09517285653887583810"
     },
     "user_tz": -120
    },
    "id": "sqRpOPoL2Emh",
    "outputId": "2f5c3367-6bd6-4639-830c-543fffd4fd3f"
   },
   "outputs": [],
   "source": [
    "# Restore the original COCO classes that YOLO was trained on into th. https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco.yaml\n",
    "\n",
    "# Update data.yaml to include the new class\n",
    "with yaml_path.open('r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "# Original COCO class names from the prompt\n",
    "original_coco_names = {\n",
    "    0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane',\n",
    "    5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light',\n",
    "    10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench',\n",
    "    14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow',\n",
    "    20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack',\n",
    "    25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee',\n",
    "    30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat',\n",
    "    35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket',\n",
    "    39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife',\n",
    "    44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich',\n",
    "    49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza',\n",
    "    54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant',\n",
    "    59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop',\n",
    "    64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave',\n",
    "    69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book',\n",
    "    74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier',\n",
    "    79: 'toothbrush'\n",
    "}\n",
    "\n",
    "\n",
    "# Combine original names with the new class\n",
    "all_class_names = original_coco_names\n",
    "all_class_names[80] = 'trash'\n",
    "\n",
    "# Update the 'names' field in the data dictionary\n",
    "data['names'] = all_class_names\n",
    "\n",
    "# Update the number of classes\n",
    "data['nc'] = len(all_class_names) # Ensure nc matches the number of names\n",
    "\n",
    "with yaml_path.open('w') as file:\n",
    "    yaml.dump(data, file, sort_keys=False) # sort_keys=False preserves the order if possible\n",
    "\n",
    "print(f\"Updated data.yaml with all class names:\")\n",
    "!cat /content/yolo_dataset/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 390944,
     "status": "ok",
     "timestamp": 1751014975480,
     "user": {
      "displayName": "Daniel Chin",
      "userId": "09517285653887583810"
     },
     "user_tz": -120
    },
    "id": "0-GvumMnKKx-",
    "outputId": "8d833750-a1de-4f62-e7d4-3bccc80f0943"
   },
   "outputs": [],
   "source": [
    "# Full COCO dataset download and merge\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# === URLs for COCO 2017 ===\n",
    "coco_image_zips = {\n",
    "    \"train\": \"http://images.cocodataset.org/zips/train2017.zip\",\n",
    "    \"val\": \"http://images.cocodataset.org/zips/val2017.zip\",\n",
    "    \"test\": \"http://images.cocodataset.org/zips/test2017.zip\"\n",
    "}\n",
    "\n",
    "coco_labels_zip_url = \"https://github.com/ultralytics/assets/releases/download/v0.0.0/coco2017labels.zip\"\n",
    "\n",
    "# === Target folders ===\n",
    "base_dir = Path(\"/content/yolo_dataset\")\n",
    "image_dirs = {\n",
    "    \"train\": base_dir / \"images\" / \"train\",\n",
    "    \"val\": base_dir / \"images\" / \"val\",\n",
    "    \"test\": base_dir / \"images\" / \"test\"\n",
    "}\n",
    "label_dirs = {\n",
    "    \"train\": base_dir / \"labels\" / \"train\",\n",
    "    \"val\": base_dir / \"labels\" / \"val\"\n",
    "}\n",
    "\n",
    "# === Temp folders ===\n",
    "temp_zip_dir = Path(\"temp_zips\")\n",
    "temp_coco_dir = Path(\"temp_coco\")\n",
    "temp_zip_dir.mkdir(exist_ok=True)\n",
    "temp_coco_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# === Download helper ===\n",
    "def download_file(url, dest):\n",
    "    if dest.exists():\n",
    "        print(f\"âœ… {dest.name} already downloaded.\")\n",
    "        return\n",
    "    print(f\"â¬‡ï¸ Downloading {url}\")\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(dest, 'wb') as f:\n",
    "            for chunk in tqdm(r.iter_content(chunk_size=8192)):\n",
    "                f.write(chunk)\n",
    "    print(f\"âœ… Downloaded {dest.name}\")\n",
    "\n",
    "# === Download COCO image zips ===\n",
    "for split, url in coco_image_zips.items():\n",
    "    zip_path = temp_zip_dir / f\"{split}2017.zip\"\n",
    "    download_file(url, zip_path)\n",
    "\n",
    "# === Download COCO YOLO-format labels zip ===\n",
    "labels_zip_path = temp_zip_dir / \"coco2017labels.zip\"\n",
    "download_file(coco_labels_zip_url, labels_zip_path)\n",
    "\n",
    "# === Extract image zips ===\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    print(f\"ðŸ“¦ Extracting COCO {split} images...\")\n",
    "    with zipfile.ZipFile(temp_zip_dir / f\"{split}2017.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(temp_coco_dir)\n",
    "\n",
    "# === Extract YOLO labels ===\n",
    "print(\"ðŸ“¦ Extracting COCO YOLO-format labels...\")\n",
    "with zipfile.ZipFile(labels_zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(temp_coco_dir)\n",
    "\n",
    "# === Move images and labels to target folders ===\n",
    "print(\"ðŸšš Moving images and labels to /content/yolo_dataset...\")\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    img_src = temp_coco_dir / f\"{split}2017\"\n",
    "    img_dst = image_dirs[split]\n",
    "    img_dst.mkdir(parents=True, exist_ok=True)\n",
    "    # Add check for files in source directory\n",
    "    print(f\"Checking for image files in {img_src}: {len(list(img_src.glob('*.jpg')))} found.\")\n",
    "    for f in tqdm(list(img_src.glob(\"*.jpg\")), desc=f\"Copying {split} images\"):\n",
    "        shutil.move(str(f), img_dst / f.name)\n",
    "\n",
    "for split in [\"train\", \"val\"]:\n",
    "    # Corrected source path to include the 'coco/' subdirectory\n",
    "    lbl_src = temp_coco_dir / \"coco\" / \"labels\" / f\"{split}2017\"\n",
    "    lbl_dst = label_dirs[split]\n",
    "    lbl_dst.mkdir(parents=True, exist_ok=True)\n",
    "    # Add check for files in source directory\n",
    "    print(f\"Checking for label files in {lbl_src}: {len(list(lbl_src.glob('*.txt')))} found.\")\n",
    "    for f in tqdm(list(lbl_src.glob(\"*.txt\")), desc=f\"Copying {split} labels\"):\n",
    "        # Check if the source label file exists before attempting to move\n",
    "        if f.exists():\n",
    "            shutil.move(str(f), lbl_dst / f.name)\n",
    "        else:\n",
    "            print(f\"âš ï¸ Warning: Label file not found for {f.name}. Skipping.\")\n",
    "\n",
    "\n",
    "# === Cleanup temp dirs ===\n",
    "shutil.rmtree(temp_coco_dir)\n",
    "print(\"\\nâœ… COCO dataset fully merged into /content/yolo_dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 27709939,
     "status": "ok",
     "timestamp": 1751043018865,
     "user": {
      "displayName": "Daniel Chin",
      "userId": "09517285653887583810"
     },
     "user_tz": -120
    },
    "id": "iDafER9bV2vH",
    "outputId": "f7519373-889f-4920-c018-5d898619e42d"
   },
   "outputs": [],
   "source": [
    "# Train a YOLO11 model with the dataset\n",
    "import shutil\n",
    "from google.colab import files\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "\n",
    "dataset_yaml = Path('/content/yolo_dataset/data.yaml')\n",
    "\n",
    "# Load a pre-trained YOLOv11n model\n",
    "model = YOLO('yolo11n.pt') # If resuming training, change this path accordingly to point to the last.pt\n",
    "\n",
    "# Get the number of original classes from the pre-trained model\n",
    "original_classes = model.model.model[-1].nc\n",
    "print(f\"Original classes in the pre-trained model: {original_classes}\")\n",
    "\n",
    "# Modify the detection head to include the new class\n",
    "# This requires accessing the last layer and adjusting its output size\n",
    "# The last layer is typically the Detect layer\n",
    "\n",
    "# Assuming the last layer is the Detect layer and has a 'nc' attribute\n",
    "if hasattr(model.model.model[-1], 'nc'):\n",
    "    # Get the current detection layer\n",
    "    detect_layer = model.model.model[-1]\n",
    "\n",
    "    # Get the configuration for the new detection layer\n",
    "    new_nc = original_classes + 1\n",
    "\n",
    "    # Directly modify the number of classes in the detect layer\n",
    "    detect_layer.nc = new_nc\n",
    "\n",
    "    # Also need to adjust the output shape for the classification head\n",
    "    # This is typically done by modifying the shape of the classification head's output\n",
    "    # within the Detect layer's forward pass or by recreating the classification head.\n",
    "    # A more reliable way in YOLOv11 is to directly adjust the convolutional layers\n",
    "    # that produce the classification output.\n",
    "\n",
    "    # In YOLOv11 Detect layer, the classification output channels are typically\n",
    "    # handled by a convolutional layer (often within a `cls` attribute)\n",
    "    # with an output size of nc * na (number of classes * number of anchors).\n",
    "    # Since 'na' is not directly accessible or used as before, we need to\n",
    "    # adjust the output shape based on the new number of classes.\n",
    "\n",
    "    # Let's try to modify the output channels of the classification convolutional layers\n",
    "    # This is based on the assumption of a common YOLOv11 Detect layer structure.\n",
    "    try:\n",
    "        # Assuming detect_layer.cv2 is a ModuleList of classification convolutional layers\n",
    "        # And assuming the output channels of these layers are proportional to the number of classes\n",
    "        for i, cv in enumerate(detect_layer.cv2):\n",
    "            # The output channels of the classification head convolution should be new_nc * na\n",
    "            # Since 'na' is not directly available, let's assume the output shape is implicitly handled\n",
    "            # by the number of classes and the input channels.\n",
    "\n",
    "            # A simpler modification is to just set the `nc` attribute and rely on\n",
    "            # the model's internal mechanisms or subsequent weight loading with strict=False.\n",
    "            pass # We already set detect_layer.nc = new_nc\n",
    "    except AttributeError:\n",
    "        print(\"Could not find attribute 'cv2' in the Detect layer. Trying a different approach.\")\n",
    "        # If cv2 is not found, the structure is different.\n",
    "        # We might need to look for other named attributes or the structure of submodules.\n",
    "\n",
    "    # Let's revert to the original plan of setting nc and relying on strict=False loading\n",
    "    # This requires having the pretrained state_dict available.\n",
    "    # Load the pre-trained state dictionary again with strict=False\n",
    "    # This might help transfer weights to the matching parts of the new layer\n",
    "    # We need to get the state_dict of the original model first.\n",
    "    original_model_for_state_dict = YOLO('yolo11n.pt')\n",
    "    pretrained_state_dict = original_model_for_state_dict.state_dict()\n",
    "\n",
    "\n",
    "    model.load_state_dict(pretrained_state_dict, strict=False)\n",
    "    print(\"State dictionary loaded with strict=False after setting nc in the Detect layer.\")\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Could not find 'nc' attribute in the last layer. Cannot modify detection head.\")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=str(dataset_yaml), epochs=50, imgsz=640, batch=-1, freeze=10) # Change epochs as required. If resuming from a previously trained model, add resume=true. last.pt will be used.\n",
    "\n",
    "print(f\"Training complete. Results saved to: {model.trainer.save_dir}\")\n",
    "\n",
    "# Get the directory where results are saved\n",
    "save_dir = Path(model.trainer.save_dir)\n",
    "print(f\"Training complete. Results saved to: {save_dir}\")\n",
    "\n",
    "# Zip the results directory\n",
    "zip_path = save_dir.with_suffix('.zip')\n",
    "shutil.make_archive(str(save_dir), 'zip', root_dir=save_dir)\n",
    "\n",
    "# Download the zipped results\n",
    "files.download(str(zip_path))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "https://github.com/astrid12345/recyclo/blob/mk_test_train/src/train_YOLO11n.ipynb",
     "timestamp": 1750846102774
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
