{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1MrV6PIxuY1kqCDeSNOdg0fz_oOqN8_qk","timestamp":1749808988344},{"file_id":"https://github.com/astrid12345/recyclo/blob/convert_taco_to_yolo/scripts/convert_taco_dataset_to_yolo_format.ipynb","timestamp":1749485102527}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["The purpose of this notebook is to convert the Aquatrash dataset to a format that can be used to train an Ultralytics YOLO model.\n","\n","# Using this notebook: workflow\n","\n","To use, make a copy of this notebook, and adapt it to work with your specific dataset. Please save your version of this ipynb file on GitHub in *recyclo/scripts*.\n","\n","(File > Save a copy in GitHub > File path = \"scripts/my_filename.ipynb\" to save notebook in scripts folder)\n","\n","Once you've generated your YOLO dataset, and are confident you can train a model with it, please upload your converted dataset to the Recyclo datasets google drive, https://drive.google.com/drive/folders/1bUkIYQRXX08OKI5TuOSg-eqntSudGaFB.\n","\n","(Why Google Drive? Because these datasets are too large for GitHub!)\n","\n","# What's in this notebook: contents\n","\n","Notebook contents:\n","- intro to YOLO\n","- intro to AquaTrash\n","- dataset specific notes (update for your specific dataset)\n","\n","# Pro tips about Colabs\n","\n","When you open the \"Files\" tab on the left, you'll find yourself in a folder containing\n","* ..\n","* sample data\n","\n","This is a colab thing, the \"content\" folder, to get you started.\n","Ignore it: click the .. to go up a level."],"metadata":{"id":"WYhAfcih9-9h"}},{"cell_type":"markdown","source":["# Intro to YOLO\n","\n","## General\n","\n","In general, YOLO models output the following for a given image:\n","* Bounding box\n","* Class label\n","* Confidence score\n","\n","To train a YOLO model, we need object detection datasets that contain images of what we're looking for (trash), and annotations: class labels and bounding boxes.\n","\n","## Ultralytics YOLO\n","\n","In this project we will use Ultralytics YOLO object detection, eg their YOLO11n model. YOLO11n is a pretrained object detection model developed by Ultralytics.\n","\n","Ultralytics YOLO expects datasets in the following format:\n","\n","```\n","dataset/\n","├── images/\n","│   ├── train/  <-- image files for training.\n","│   ├── val/    <-- image files for validation after each epoch. Must not overlap with images in train.\n","|   └── test/   <-- optional: can put some image files here for benchmarking.\n","├── labels/\n","│   ├── train/  <-- one .txt file per train image (must have same name). Contains class and bbox info..\n","│   ├── val/    <-- one .txt file per val image.\n","|   └── test/   <-- one .txt file per test image.\n","└── data.yaml   <-- config file; helps tie all the above together.\n","```\n","\n","Example labels/train file:\n","```\n","<class_id> <x_center> <y_center> <width> <height>\n","```\n","\n","Example data.yaml file:\n","```\n","path: /content/dataset  # Root folder\n","train: images/train\n","val: images/val\n","\n","nc: 5  # number of classes\n","names: ['bottle', 'can', 'plastic bag', 'wrapper', 'paper']\n","\n","```"],"metadata":{"id":"x347PAo8rkYn"}},{"cell_type":"markdown","source":["\n","---\n","⚠️‼️ ***THE SECTION TO CHANGE FOR YOUR SPECIFIC DATASET STARTS HERE*** ‼️⚠️\n","\n","The sections above apply for all dataset conversions.\n","\n","---"],"metadata":{"id":"GUP0h7VX_seR"}},{"cell_type":"code","source":["# ✏️ Enter your dataset-specific code here\n","# This cell is for importing your dataset to the notebook, and defining its name and path.\n","\n","from pathlib import Path\n","\n","dataset_name = \"AquaTrash\"\n","dataset_path = Path('/content/AquaTrash_dataset')\n","if not dataset_path.exists():\n","    print(f\"Cloning AquaTrash dataset to {dataset_path}...\")\n","    !git clone https://github.com/Harsh9524/AquaTrash.git /content/AquaTrash_dataset\n","    print(f\"Dataset downloaded to {dataset_path}\\n\")\n","else:\n","    print(f\"Dataset directory {dataset_path} already exists. Skipping clone.\\n\")\n","\n","print(f\"{dataset_name} dataset downloaded to {dataset_path}\\n\")"],"metadata":{"id":"DwT18ruVap0W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# AquaTrash dataset\n","✏️ Modify this section for your specific dataset.\n","\n","The AquaTrash dataset uses an unusual formatting. It has an annotations.json file that contains the labelling information in the format of\n","\n","```\n","<image name> <x_min> <y_min> <x_max> <y_max> <class_name>\n","```\n","\n","## Conversion\n","To convert the AquaTrash dataset to a format ultralytics YOLO can use, we must:\n","* Split the images into train, val, and test sets\n","* Extract label and bbox info from annotations.csv, convert it to\n","\n","```\n","<class_id> <x_center> <y_center> <width> <height>\n","```\n","* Make a data.yaml file"],"metadata":{"id":"f7u6PWyfxeLD"}},{"cell_type":"code","source":["import shutil\n","from pathlib import Path\n","import pandas as pd\n","from PIL import Image\n","dataset_name = \"AquaTrash\"\n","dataset_path = Path('/content/AquaTrash_dataset')\n","source_images_path = dataset_path / 'Images'\n","annotations_path = dataset_path / 'annotations.csv'\n","n_total = sum(1 for _ in source_images_path.glob('*.jpg'))  # a quick way to find out how many files are in the Images folder\n","# Set up output folder system\n","output_root = dataset_path.parent / f\"{dataset_name}_yolo_{n_total}\"\n","yolo_img_dirs = {\n","    'train': output_root / 'images' / 'train',\n","    'val': output_root / 'images' / 'val',\n","    'test': output_root / 'images' / 'test',\n","}\n","yolo_lbl_dirs = {\n","    'train': output_root / 'labels' / 'train',\n","    'val': output_root / 'labels' / 'val',\n","    'test': output_root / 'labels' / 'test',\n","}\n","# Clear and recreate folders if the script is run a 2nd time\n","for d in list(yolo_img_dirs.values()) + list(yolo_lbl_dirs.values()):\n","    if d.exists():\n","        shutil.rmtree(d)\n","    d.mkdir(parents=True, exist_ok=True)\n","# Load annotations\n","df = pd.read_csv(annotations_path)\n","default_class_id = 0              # We decided to only use one class, 'trash', so all labels will have a class ID of 0\n","grouped = df.groupby('image_name') # Group annotations by image, since one image often has multiple labels in the csv\n","grouped = list(df.groupby('image_name'))  # convert to list so shuffle works\n","# Compute dataset split\n","n_train = int(0.8 * len(grouped)) # 80% of the images to training\n","n_val = int(0.1 * len(grouped))   # 10% to val\n","n_test = len(grouped) - n_train - n_val  # the rest to test\n","splits = ['train'] * n_train + ['val'] * n_val + ['test'] * n_test\n","# Process each image\n","for i, ((file_path, group), split) in enumerate(zip(grouped, splits)):\n","    src_img_path = source_images_path / Path(file_path).name\n","    if not src_img_path.exists():\n","        print(f\"Warning: {src_img_path} not found, skipping.\")\n","        continue\n","    # Open image to get dimensions\n","    with Image.open(src_img_path) as img:\n","        width, height = img.size\n","    # Let's rename the file's while we're at it\n","    base_name = f\"{dataset_name}_{i:06}\"\n","    new_img_name = base_name + \".jpg\"\n","    new_lbl_name = base_name + \".txt\"\n","    # Copy image to destination YOLO folder (train, val, or test)\n","    shutil.copy(src_img_path, yolo_img_dirs[split] / new_img_name)\n","    # Convert label data to YOLO format, and write it to the corresponding label file\n","    label_lines = []\n","    for _, row in group.iterrows():\n","        x_min, y_min, x_max, y_max = row[['x_min', 'y_min', 'x_max', 'y_max']]\n","        x_center = ((x_min + x_max) / 2) / width\n","        y_center = ((y_min + y_max) / 2) / height\n","        box_width = (x_max - x_min) / width\n","        box_height = (y_max - y_min) / height\n","        label_lines.append(f\"{default_class_id} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f}\")\n","    with open(yolo_lbl_dirs[split] / new_lbl_name, 'w') as f:\n","        f.write('\\n'.join(label_lines))\n","# generate data.yaml\n","data_yaml_path = output_root / 'data.yaml'\n","with open(data_yaml_path, 'w') as f:\n","    f.write(\"names: ['trash']\\n\")\n","    f.write(\"nc: 1\\n\")\n","    f.write(f\"path: {output_root}\\n\")\n","    f.write(\"train: images/train\\n\")\n","    f.write(\"val: images/val\\n\")\n","    f.write(\"test: images/test\\n\")\n","print(f\"Converted {len(grouped)} images to YOLO format with 80/10/10 train/val/test split at: {output_root}\")"],"metadata":{"id":"Usb6nID5YC8i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","---\n","⚠️‼️ ***THE SECTION TO CHANGE FOR YOUR SPECIFIC DATASET STOPS HERE*** ‼️⚠️\n","\n","The sections below apply for all dataset conversions.\n","\n","---"],"metadata":{"id":"osDjmxq9FhmP"}},{"cell_type":"markdown","source":["To verify that your conversion worked, make sure you can train a model and that it outputs images with a bounding box and label."],"metadata":{"id":"xpsMcME2-rDs"}},{"cell_type":"code","source":["# ⚠️ DO NOT MODIFY THIS CELL\n","# This cell imports the ultralytics library required for training a model\n","\n","!pip install -U ultralytics\n","\n","from ultralytics import YOLO\n","import os"],"metadata":{"collapsed":true,"id":"Mb5g0TegvNCl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ⚠️ DO NOT MODIFY THIS CELL\n","# This cell trains a YOLO model on the converted YOLO dataset to see if it's set up correctly\n","# Tip: inspect the output of this cell to assess whether training occured properly.\n","\n","model = YOLO('yolo11n.pt')\n","# Use the output_root directly as the data path\n","results = model.train(data=str(output_root / 'data.yaml'), epochs=20, imgsz=640)  # epoch size is small - this is just to see if it can work!"],"metadata":{"collapsed":true,"id":"UL4rIlXU-oLt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["If the model outputs even one image with a bounding box and label, then the dataset should work for our project! Verify this using the code below."],"metadata":{"id":"2JPNfPNAEtFK"}},{"cell_type":"code","source":["# ⚠️ DO NOT MODIFY THIS CELL\n","# This cell passes the trained model some images, to see if the model can identify some trash\n","\n","import cv2\n","from random import sample\n","import matplotlib.pyplot as plt\n","import os # Moved import here\n","\n","# Get the latest model\n","runs_detect_dir = Path('runs/detect')\n","train_dirs = [d for d in runs_detect_dir.iterdir() if d.is_dir() and d.name.startswith(\"train\")]\n","train_dirs.sort(key=lambda d: d.stat().st_mtime, reverse=True)  # sort by modification time\n","latest_train_dir = train_dirs[0]\n","best_model_path = latest_train_dir / 'weights' / 'best.pt'\n","print(f\"Loading {best_model_path}\")\n","\n","# Load the model and try it out\n","model = YOLO(best_model_path)\n","train_images_path = output_root / \"images\" / \"train\" # Corrected path to use output_root\n","image_files = list(train_images_path.glob('*.jpg'))\n","\n","sample_images = sample(image_files, 10)\n","\n","for image_path in sample_images:\n","    result = model(image_path)[0]\n","    annotated_image = result.plot()\n","\n","    plt.figure(figsize=(8, 6))\n","    plt.imshow(annotated_image)\n","    plt.title(f'Predictions: {image_path.name}')\n","    plt.axis('off')\n","    plt.show()"],"metadata":{"collapsed":true,"id":"Apy8pfX6Eyhe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["If the model successfully generated even one image with a bounding box and label, please run the following code block to zip the yolo dataset, download the zipped file, and upload it on Google Drive, https://www.google.com/url?q=https%3A%2F%2Fdrive.google.com%2Fdrive%2Ffolders%2F1bUkIYQRXX08OKI5TuOSg-eqntSudGaFB."],"metadata":{"id":"zj5c-mtlL2gk"}},{"cell_type":"code","source":["# ⚠️ DO NOT MODIFY THIS CELL\n","# This cell zips your converted YOLO dataset with an informative name, so you can download it and upload it to google drive.\n","\n","from datetime import datetime\n","from pathlib import Path\n","import os\n","\n","# Generate date prefix\n","date_str = datetime.now().strftime('%Y%m%d')\n","\n","# Define the folder to zip (the final YOLO dataset folder)\n","folder_to_zip = output_root # output_root is set to the path of the generated YOLO dataset\n","\n","# Define the name of the output zip file\n","# Using the parent directory name in the zip name might be confusing if the folder to zip is the final output\n","# Let's use the folder_to_zip name directly for the zip name prefix\n","zip_name = f\"{date_str}_{folder_to_zip.name}.zip\"\n","\n","# Define the full path for the output zip file\n","output_zip_path = Path('/content') / zip_name\n","\n","# Change directory to the parent of the folder to zip so the zip command includes the folder itself\n","# Or, more simply, use the zip command directly on the folder_to_zip path\n","# %cd {folder_to_zip.parent} # No need to change directory if zipping directly\n","\n","print(f\"Creating zip archive from {folder_to_zip}...\")\n","\n","# Use the zip command to archive the specific folder\n","# The -r flag is for recursive zipping (includes subdirectories)\n","# The first argument is the output zip file path\n","# The second argument is the folder to be zipped (relative to the current directory or absolute path)\n","# We will use the absolute path to the folder_to_zip\n","!zip -r {output_zip_path} {folder_to_zip}\n","\n","print(f\"Zip created at {output_zip_path}\")"],"metadata":{"collapsed":true,"id":"Ik8EKrBMLyap"},"execution_count":null,"outputs":[]}]}