{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Reading 3 zipped datasets from Google Drive and unzipping them\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Specify the path to the folder in your Google Drive after adding a shortcut\n",
        "drive_folder_path = '/content/drive/MyDrive/Recyclo/datasets'\n",
        "\n",
        "# List to store the names of found zip files\n",
        "found_zip_files = []\n",
        "\n",
        "# Initialize the list to store extracted dataset names *before* the loop\n",
        "extracted_dataset_names = []\n",
        "\n",
        "# Check if the directory exists before listing its contents\n",
        "if not os.path.exists(drive_folder_path):\n",
        "    print(f\"Error: The directory '{drive_folder_path}' was not found.\")\n",
        "    print(\"Please ensure you have added a shortcut to the shared folder in your 'My Drive' and the path is correct.\")\n",
        "else:\n",
        "    # List all files in the folder\n",
        "    for filename in os.listdir(drive_folder_path):\n",
        "      if filename.endswith(\".zip\"):\n",
        "        # Add the found zip file name to the list\n",
        "        found_zip_files.append(filename)\n",
        "\n",
        "        zip_path = os.path.join(drive_folder_path, filename)\n",
        "\n",
        "        # Create a directory to extract to (optional)\n",
        "        # Ensure the filename is clean for directory naming\n",
        "        safe_filename = filename.replace('.zip', '')\n",
        "        extract_path = f'/content/{safe_filename}_extracted'\n",
        "        # Append the extracted path to the list *within* the loop\n",
        "        extracted_dataset_names.append(extract_path)\n",
        "\n",
        "        os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "        # Open the zip file\n",
        "        try:\n",
        "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "              # Extract all the contents into the specified directory\n",
        "              zip_ref.extractall(extract_path)\n",
        "              print(f\"Extracted {filename} to {extract_path}\")\n",
        "        except zipfile.BadZipFile:\n",
        "            print(f\"Error: {filename} is not a valid zip file.\")\n",
        "        except FileNotFoundError:\n",
        "             print(f\"Error: Zip file not found at {zip_path}. This is unexpected after listing the directory.\")\n",
        "\n",
        "        # You can now process the extracted files in 'extract_path'\n",
        "\n",
        "# Optional: Print the list of found zip files after the loop\n",
        "print(\"\\nFound the following zip files:\")\n",
        "for zip_name in found_zip_files:\n",
        "    print(f\"- {zip_name}\")\n",
        "\n",
        "print(\"\\nExtracted dataset names:\")\n",
        "for name in extracted_dataset_names:\n",
        "  print(f\"- {name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8HefqSf7RbJ",
        "outputId": "af0562c5-33b8-4993-8a18-f5e47b55c60a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Extracted 20250602_aquatrash_yolo.zip to /content/20250602_aquatrash_yolo_extracted\n",
            "Extracted 20250602z_mju-waste_yolo.zip to /content/20250602z_mju-waste_yolo_extracted\n",
            "Extracted 20250603_TACO_yolo_1500.zip to /content/20250603_TACO_yolo_1500_extracted\n",
            "\n",
            "Found the following zip files:\n",
            "- 20250602_aquatrash_yolo.zip\n",
            "- 20250602z_mju-waste_yolo.zip\n",
            "- 20250603_TACO_yolo_1500.zip\n",
            "\n",
            "Extracted dataset names:\n",
            "- /content/20250602_aquatrash_yolo_extracted\n",
            "- /content/20250602z_mju-waste_yolo_extracted\n",
            "- /content/20250603_TACO_yolo_1500_extracted\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# List of directories to delete\n",
        "directories_to_delete = [\n",
        "    '/content/20250602z_mju-waste_yolo_extracted',\n",
        "    '/content/20250602_aquatrash_yolo_extracted',\n",
        "    '/content/20250603_TACO_yolo_1500_extracted',\n",
        "    '/content/merged_yolo_dataset'\n",
        "] # Replace with your actual list of folder paths\n",
        "\n",
        "for directory_path in directories_to_delete:\n",
        "    if os.path.exists(directory_path):\n",
        "        try:\n",
        "            shutil.rmtree(directory_path)\n",
        "            print(f\"Deleted directory and its contents: {directory_path}\")\n",
        "        except OSError as e:\n",
        "            print(f\"Error deleting directory {directory_path}: {e}\")\n",
        "    else:\n",
        "        print(f\"Directory not found: {directory_path}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWhAwxS3dz3I",
        "outputId": "1ea42f54-7ddf-478a-9e0d-80e99c243d9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted directory and its contents: /content/20250602z_mju-waste_yolo_extracted\n",
            "Deleted directory and its contents: /content/20250602_aquatrash_yolo_extracted\n",
            "Deleted directory and its contents: /content/20250603_TACO_yolo_1500_extracted\n",
            "Deleted directory and its contents: /content/merged_yolo_dataset\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# %%\n",
        "import os\n",
        "import shutil\n",
        "import yaml # You might need to install PyYAML: pip install PyYAML\n",
        "\n",
        "# --- Configuration ---\n",
        "# List of paths to the extracted YOLOv8 datasets.\n",
        "# This list is now populated correctly from the previous code block.\n",
        "extracted_yolo_dataset_paths = extracted_dataset_names\n",
        "\n",
        "# Subdirectories expected within each YOLOv8 dataset\n",
        "yolo_image_subdirs = ['images/train', 'images/val', 'images/test'] # Add 'test' if applicable\n",
        "yolo_label_subdirs = ['labels/train', 'labels/val', 'labels/test'] # Add 'test' if applicable\n",
        "\n",
        "# Output directory for the merged YOLOv8 dataset\n",
        "merged_output_dir = '/content/merged_yolo_dataset'\n",
        "\n",
        "# Define a mapping for merging class names\n",
        "# Key: original class name from a dataset\n",
        "# Value: the desired class name in the merged dataset\n",
        "class_name_mapping = {\n",
        "    'Rubbish': 'trash', # Map 'rubbish' from any dataset to 'trash'\n",
        "    'trash': 'trash',\n",
        "    'glass': 'trash',\n",
        "    'metal': 'trash',\n",
        "    'paper': 'trash',\n",
        "    'plastic': 'trash'\n",
        "    # Ensure 'trash' is also mapped to 'trash' (optional, but good practice)\n",
        "    # Add mappings for other classes if needed, e.g.:\n",
        "    # 'plastic_bottle': 'bottle',\n",
        "    # 'glass_bottle': 'bottle',\n",
        "}\n",
        "\n",
        "\n",
        "# --- Merging Process ---\n",
        "\n",
        "# Create the main merged directories\n",
        "merged_images_base = os.path.join(merged_output_dir, 'images')\n",
        "merged_labels_base = os.path.join(merged_output_dir, 'labels')\n",
        "\n",
        "# Create train, val, test subdirectories within the merged structure\n",
        "for subdir in ['train', 'val', 'test']:\n",
        "    os.makedirs(os.path.join(merged_images_base, subdir), exist_ok=True)\n",
        "    os.makedirs(os.path.join(merged_labels_base, subdir), exist_ok=True)\n",
        "\n",
        "# Keep track of encountered class names and map them to new indices\n",
        "# This assumes all datasets use consistent class names, even if indices differ.\n",
        "# If names differ for the same object, you'll need a manual mapping.\n",
        "class_names_set = set()\n",
        "merged_class_names = []\n",
        "class_name_to_id = {}\n",
        "next_class_id = 0\n",
        "\n",
        "# Map to track image/label file renames due to conflicts (optional but safe)\n",
        "# Example: {'original_name.jpg': 'dataset1_original_name.jpg'}\n",
        "renamed_files_map = {}\n",
        "\n",
        "print(\"Starting YOLO dataset merging...\")\n",
        "\n",
        "for dataset_path in extracted_yolo_dataset_paths:\n",
        "    print(f\"Processing dataset: {dataset_path}\")\n",
        "\n",
        "    # --- Process Class Names ---\n",
        "    # Load data.yaml from the current dataset to get class names\n",
        "    data_yaml_path = os.path.join(dataset_path, 'data.yaml')\n",
        "    current_class_names = []\n",
        "    current_class_id_to_name = {}\n",
        "\n",
        "    if os.path.exists(data_yaml_path):\n",
        "        try:\n",
        "            with open(data_yaml_path, 'r') as f:\n",
        "                current_data_yaml = yaml.safe_load(f)\n",
        "                current_class_names = current_data_yaml.get('names', [])\n",
        "                # Create a map from original ID to name for this dataset\n",
        "                current_class_id_to_name = {i: name for i, name in enumerate(current_class_names)}\n",
        "\n",
        "            # --- Apply Class Name Mapping and Build Merged Class List ---\n",
        "            for original_class_name in current_class_names:\n",
        "                # Apply the mapping\n",
        "                merged_class_name = class_name_mapping.get(original_class_name, original_class_name) # Use original if not in mapping\n",
        "\n",
        "                if merged_class_name not in class_names_set:\n",
        "                    class_names_set.add(merged_class_name)\n",
        "                    merged_class_names.append(merged_class_name)\n",
        "                    class_name_to_id[merged_class_name] = next_class_id\n",
        "                    next_class_id += 1\n",
        "            print(f\"  Found {len(current_class_names)} original classes. Merged classes now: {len(merged_class_names)}\")\n",
        "\n",
        "            if current_class_names:\n",
        "                print(f\"  Original classes found in {os.path.basename(dataset_path)}:\")\n",
        "                for i, name in enumerate(current_class_names):\n",
        "                    # Also show how they are mapped\n",
        "                    mapped_name = class_name_mapping.get(name, name)\n",
        "                    print(f\"    - Original ID: {i}, Original Name: {name} -> Mapped Name: {mapped_name}\")\n",
        "\n",
        "        except FileNotFoundError:\n",
        "             print(f\"  Warning: data.yaml not found at {data_yaml_path}. Cannot get class names from this dataset.\")\n",
        "             # Continue processing files but cannot map class IDs correctly if no data.yaml\n",
        "             current_class_names = []\n",
        "             current_class_id_to_name = {}\n",
        "        except Exception as e:\n",
        "             print(f\"  Error loading data.yaml from {data_yaml_path}: {e}. Skipping class processing for this dataset.\")\n",
        "             current_class_names = []\n",
        "             current_class_id_to_name = {}\n",
        "    else:\n",
        "         print(f\"  Warning: data.yaml not found at {data_yaml_path}. Cannot get class names from this dataset.\")\n",
        "         current_class_names = []\n",
        "         current_class_id_to_name = {}\n",
        "\n",
        "\n",
        "    # --- Copy Images and Labels ---\n",
        "    for i, subdir in enumerate(['train', 'val', 'test']):\n",
        "        original_images_path = os.path.join(dataset_path, yolo_image_subdirs[i])\n",
        "        original_labels_path = os.path.join(dataset_path, yolo_label_subdirs[i])\n",
        "        merged_images_path = os.path.join(merged_images_base, subdir)\n",
        "        merged_labels_path = os.path.join(merged_labels_base, subdir)\n",
        "\n",
        "        if not os.path.exists(original_images_path):\n",
        "            print(f\"  Warning: Image directory not found: {original_images_path}. Skipping {subdir} for this dataset.\")\n",
        "            continue\n",
        "        if not os.path.exists(original_labels_path):\n",
        "            print(f\"  Warning: Label directory not found: {original_labels_path}. Skipping {subdir} for this dataset.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"  Copying {subdir} images and labels...\")\n",
        "\n",
        "        for filename in os.listdir(original_images_path):\n",
        "            img_name, img_ext = os.path.splitext(filename)\n",
        "            label_filename = img_name + '.txt'\n",
        "\n",
        "            original_image_file = os.path.join(original_images_path, filename)\n",
        "            original_label_file = os.path.join(original_labels_path, label_filename)\n",
        "\n",
        "            # Check if corresponding label file exists\n",
        "            if not os.path.exists(original_label_file):\n",
        "                print(f\"    Warning: Label file not found for image {filename} at {original_labels_path}. Skipping this image and its missing label.\")\n",
        "                continue\n",
        "\n",
        "            # --- Handle File Name Conflicts ---\n",
        "            new_img_filename = filename\n",
        "            new_label_filename = label_filename\n",
        "\n",
        "            # Check if a file with this name already exists in the destination\n",
        "            merged_dest_image_path = os.path.join(merged_images_path, new_img_filename)\n",
        "            merged_dest_label_path = os.path.join(merged_labels_path, new_label_filename)\n",
        "\n",
        "            # Simple conflict check: Does a file with this name already exist in the destination?\n",
        "            # A more robust check would compare file hashes if the same name could mean different images.\n",
        "            if os.path.exists(merged_dest_image_path) or os.path.exists(merged_dest_label_path):\n",
        "                 # Conflict detected, rename the files\n",
        "                 # Using a simple prefix like 'dataset_index_' or a hash\n",
        "                 prefix = f\"{len(renamed_files_map.keys())}_\" # Use a simple counter for uniqueness\n",
        "                 new_img_filename = prefix + filename\n",
        "                 new_label_filename = prefix + label_filename\n",
        "                 renamed_files_map[filename] = new_img_filename # Store original to new mapping\n",
        "                 print(f\"    Conflict for {filename}. Renaming to {new_img_filename}\")\n",
        "\n",
        "                 merged_dest_image_path = os.path.join(merged_images_path, new_img_filename)\n",
        "                 merged_dest_label_path = os.path.join(merged_labels_path, new_label_filename)\n",
        "\n",
        "\n",
        "            # --- Copy Files ---\n",
        "            try:\n",
        "                shutil.copy2(original_image_file, merged_dest_image_path)\n",
        "                shutil.copy2(original_label_file, merged_dest_label_path)\n",
        "\n",
        "                # --- Update Class Indices in Label File ---\n",
        "                # Only process label files if we successfully loaded class names for this dataset\n",
        "                if current_class_id_to_name:\n",
        "                     updated_lines = []\n",
        "                     with open(merged_dest_label_path, 'r') as f: # This line was causing the error\n",
        "                         for line in f:\n",
        "                             parts = line.strip().split()\n",
        "                             if parts:\n",
        "                                 try:\n",
        "                                     original_class_id = int(parts[0])\n",
        "                                     # Get the original class name using the original ID map for this dataset\n",
        "                                     original_class_name = current_class_id_to_name.get(original_class_id)\n",
        "\n",
        "                                     if original_class_name is not None:\n",
        "                                         # Get the mapped class name\n",
        "                                         merged_class_name = class_name_mapping.get(original_class_name, original_class_name)\n",
        "\n",
        "                                         if merged_class_name in class_name_to_id:\n",
        "                                             # Get the new class ID from the merged map\n",
        "                                             new_class_id = class_name_to_id[merged_class_name]\n",
        "                                             # Replace the original class ID with the new one\n",
        "                                             parts[0] = str(new_class_id)\n",
        "                                             updated_lines.append(\" \".join(parts))\n",
        "                                         else:\n",
        "                                              print(f\"    Warning: Mapped class name '{merged_class_name}' (original: '{original_class_name}') not found in merged class map for {label_filename}. Skipping this annotation line.\")\n",
        "                                              pass # Skip the annotation line\n",
        "                                     else:\n",
        "                                          print(f\"    Warning: Original class ID {original_class_id} not found in original class map for {label_filename}. Skipping this annotation line.\")\n",
        "                                          pass # Skip the annotation line\n",
        "                                 except ValueError:\n",
        "                                     print(f\"    Warning: Invalid class ID format in label file {label_filename} line: '{line.strip()}'. Skipping this line.\")\n",
        "                                     pass # Skip lines with invalid format\n",
        "                                 except Exception as line_e:\n",
        "                                     print(f\"    Error processing line '{line.strip()}' in {label_filename}: {line_e}. Skipping this line.\")\n",
        "                                     pass # Skip lines with other errors\n",
        "\n",
        "\n",
        "                     # Write the updated lines back to the label file\n",
        "                     with open(merged_dest_label_path, 'w') as f:\n",
        "                         f.write(\"\\n\".join(updated_lines))\n",
        "\n",
        "            except FileNotFoundError:\n",
        "                 print(f\"    Error copying files for {filename}. Image or label file not found unexpectedly.\")\n",
        "            except Exception as e:\n",
        "                 print(f\"    Error processing file {filename}: {e}\")\n",
        "\n",
        "\n",
        "print(\"YOLO dataset merging complete.\")\n",
        "\n",
        "# --- Create Merged data.yaml ---\n",
        "print(\"Creating merged data.yaml...\")\n",
        "\n",
        "merged_data_yaml = {\n",
        "    'path': merged_output_dir,\n",
        "    'train': os.path.join(merged_images_base, 'train'),\n",
        "    'val': os.path.join(merged_images_base, 'val'),\n",
        "    # 'test': os.path.join(merged_images_base, 'test'), # Include if you have test data\n",
        "    'nc': len(merged_class_names),\n",
        "    'names': merged_class_names\n",
        "}\n",
        "\n",
        "# Save the merged data.yaml file\n",
        "merged_data_yaml_path = os.path.join(merged_output_dir, 'data.yaml')\n",
        "with open(merged_data_yaml_path, 'w') as f:\n",
        "    yaml.dump(merged_data_yaml, f, sort_keys=False) # Use sort_keys=False to keep names order\n",
        "\n",
        "print(f\"Merged data.yaml saved to: {merged_data_yaml_path}\")\n",
        "print(f\"Total classes in merged dataset: {len(merged_class_names)}\")\n",
        "print(f\"Merged class names: {merged_class_names}\")\n",
        "\n",
        "# --- Next Steps ---\n",
        "print(\"\\nNext Steps:\")\n",
        "print(f\"1. Your merged YOLOv8 dataset is located at: {merged_output_dir}\")\n",
        "print(f\"2. The data.yaml file is in: {merged_data_yaml_path}\")\n",
        "print(\"3. You can now use this merged dataset for training with YOLOv8.\")\n",
        "print(\"   Point your YOLOv8 training command to this data.yaml file.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gty4vl3AiXo0",
        "outputId": "efd9adb7-3a5d-48d0-c061-195d5e530fd1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting YOLO dataset merging...\n",
            "Processing dataset: /content/20250602_aquatrash_yolo_extracted\n",
            "  Found 4 original classes. Merged classes now: 1\n",
            "  Original classes found in 20250602_aquatrash_yolo_extracted:\n",
            "    - Original ID: 0, Original Name: glass -> Mapped Name: trash\n",
            "    - Original ID: 1, Original Name: metal -> Mapped Name: trash\n",
            "    - Original ID: 2, Original Name: paper -> Mapped Name: trash\n",
            "    - Original ID: 3, Original Name: plastic -> Mapped Name: trash\n",
            "  Copying train images and labels...\n",
            "  Copying val images and labels...\n",
            "  Warning: Image directory not found: /content/20250602_aquatrash_yolo_extracted/images/test. Skipping test for this dataset.\n",
            "Processing dataset: /content/20250602z_mju-waste_yolo_extracted\n",
            "  Found 1 original classes. Merged classes now: 1\n",
            "  Original classes found in 20250602z_mju-waste_yolo_extracted:\n",
            "    - Original ID: 0, Original Name: Rubbish -> Mapped Name: trash\n",
            "  Copying train images and labels...\n",
            "    Warning: Label file not found for image 2019-12-10_16_14_32-04_color.png at /content/20250602z_mju-waste_yolo_extracted/labels/train. Skipping this image and its missing label.\n",
            "    Warning: Label file not found for image 2019-12-04_16_24_27-41_color.png at /content/20250602z_mju-waste_yolo_extracted/labels/train. Skipping this image and its missing label.\n",
            "    Warning: Label file not found for image 2019-09-19_16_20_30-29_color.png at /content/20250602z_mju-waste_yolo_extracted/labels/train. Skipping this image and its missing label.\n",
            "    Warning: Label file not found for image 2019-12-10_16_34_16-66_color.png at /content/20250602z_mju-waste_yolo_extracted/labels/train. Skipping this image and its missing label.\n",
            "    Warning: Label file not found for image 2019-09-19_16_20_37-17_color.png at /content/20250602z_mju-waste_yolo_extracted/labels/train. Skipping this image and its missing label.\n",
            "    Warning: Label file not found for image 2019-12-04_16_17_40-33_color.png at /content/20250602z_mju-waste_yolo_extracted/labels/train. Skipping this image and its missing label.\n",
            "    Warning: Label file not found for image 2019-12-04_16_20_08-09_color.png at /content/20250602z_mju-waste_yolo_extracted/labels/train. Skipping this image and its missing label.\n",
            "    Warning: Label file not found for image 2019-09-19_16_37_35-52_color.png at /content/20250602z_mju-waste_yolo_extracted/labels/train. Skipping this image and its missing label.\n",
            "  Copying val images and labels...\n",
            "  Copying test images and labels...\n",
            "Processing dataset: /content/20250603_TACO_yolo_1500_extracted\n",
            "  Found 1 original classes. Merged classes now: 1\n",
            "  Original classes found in 20250603_TACO_yolo_1500_extracted:\n",
            "    - Original ID: 0, Original Name: trash -> Mapped Name: trash\n",
            "  Copying train images and labels...\n",
            "  Copying val images and labels...\n",
            "  Copying test images and labels...\n",
            "YOLO dataset merging complete.\n",
            "Creating merged data.yaml...\n",
            "Merged data.yaml saved to: /content/merged_yolo_dataset/data.yaml\n",
            "Total classes in merged dataset: 1\n",
            "Merged class names: ['trash']\n",
            "\n",
            "Next Steps:\n",
            "1. Your merged YOLOv8 dataset is located at: /content/merged_yolo_dataset\n",
            "2. The data.yaml file is in: /content/merged_yolo_dataset/data.yaml\n",
            "3. You can now use this merged dataset for training with YOLOv8.\n",
            "   Point your YOLOv8 training command to this data.yaml file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ibA-0J3NfsYg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}