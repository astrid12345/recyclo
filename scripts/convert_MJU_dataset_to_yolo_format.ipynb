{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b072aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.146  Python-3.11.9 torch-2.6.0+cu118 CUDA:0 (GeForce GTX 1650, 4096MiB)\n",
      "Setup complete  (12 CPUs, 15.9 GB RAM, 144.3/931.5 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from ultralytics import YOLO\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c6d1ca",
   "metadata": {},
   "source": [
    "Only run this notebook once, after running restructure_MJU_annotations.ipynb\n",
    "\n",
    "This script converts COCO to YOLO\n",
    "In results, a few random images are shown with their bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00a52ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell sets up the function that converts the simple COCO dataset to YOLO format\n",
    "\n",
    "def convert_coco_to_yolo(coco_root: Path, dataset_name: str, train_split: float = 0.8):\n",
    "    \"\"\"\n",
    "    Converts a simple COCO dataset to YOLOv8 format, including train/val split and data.yaml generation.\n",
    "\n",
    "    Args:\n",
    "        coco_root (Path): Path to the root of the simple COCO dataset (should contain images/ and annotations.json).\n",
    "        dataset_name (str): Name of the output dataset folder (e.g., \"taco\" -> creates \"taco_yolo\").\n",
    "        train_split (float, optional): Fraction of images to use for training. Defaults to 0.8.\n",
    "          The remaining images are split between validation and testing.\n",
    "\n",
    "    Returns:\n",
    "        Path: Path to the data.yaml file\n",
    "    \"\"\"\n",
    "    # Paths\n",
    "    coco_json_path = coco_root / 'annotations.json'\n",
    "    coco_images_path = coco_root / 'images'\n",
    "\n",
    "    # Load COCO JSON and get number of images for naming\n",
    "    with open(coco_json_path, 'r') as f:\n",
    "        coco = json.load(f)\n",
    "    n_total = len(coco['images'])\n",
    "\n",
    "    # Paths YOLO\n",
    "    yolo_root = coco_root.parent / f\"{dataset_name}_yolo_{n_total}_renametest\"\n",
    "    yolo_img_dirs = {\n",
    "        'train': yolo_root / 'images' / 'train',\n",
    "        'val': yolo_root / 'images' / 'val',\n",
    "        'test': yolo_root / 'images' / 'test',\n",
    "    }\n",
    "    yolo_lbl_dirs = {\n",
    "        'train': yolo_root / 'labels' / 'train',\n",
    "        'val': yolo_root / 'labels' / 'val',\n",
    "        'test': yolo_root / 'labels' / 'test',\n",
    "    }\n",
    "\n",
    "    # Clear and recreate folders\n",
    "    for d in list(yolo_img_dirs.values()) + list(yolo_lbl_dirs.values()):\n",
    "        if d.exists():\n",
    "            shutil.rmtree(d)\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Map image_id -> metadata\n",
    "    image_info = {img['id']: (img['width'], img['height'], img['file_name']) for img in coco['images']}\n",
    "\n",
    "    # Map image_id -> annotations\n",
    "    annots_per_image = defaultdict(list)\n",
    "    for ann in coco['annotations']:\n",
    "        annots_per_image[ann['image_id']].append(ann)\n",
    "\n",
    "    # Shuffle and split image IDs\n",
    "    all_image_ids = list(image_info.keys())\n",
    "    random.shuffle(all_image_ids)\n",
    "\n",
    "    # Assign a unique sequence number to each image_id\n",
    "    id_to_seq = {image_id: f\"{i+1:06}\" for i, image_id in enumerate(all_image_ids)}\n",
    "\n",
    "    n_train = int(n_total * train_split)\n",
    "    n_val = int((n_total - n_train) / 2)\n",
    "    n_test = n_total - n_train - n_val\n",
    "\n",
    "    split_ids = {\n",
    "        'train': set(all_image_ids[:n_train]),\n",
    "        'val': set(all_image_ids[n_train:n_train + n_val]),\n",
    "        'test': set(all_image_ids[n_train + n_val:]),\n",
    "    }\n",
    "\n",
    "    def write_labels_and_copy_images(image_ids, img_dir, lbl_dir):\n",
    "        for image_id in image_ids:\n",
    "            width, height, filename = image_info[image_id]\n",
    "            orig_stem = id_to_seq[image_id]  # adapated, use consistent global sequential ID for naming convention\n",
    "            new_stem = f\"{dataset_name}_{orig_stem}\"\n",
    "            label_path = lbl_dir / f\"{new_stem}.txt\"\n",
    "            image_src = coco_images_path / filename\n",
    "            image_dst = img_dir / f\"{new_stem}.jpg\"\n",
    "\n",
    "            if image_src.exists():\n",
    "                shutil.copy(image_src, image_dst)\n",
    "            else:\n",
    "                print(f\"Warning: Image not found: {image_src}\")\n",
    "                continue\n",
    "\n",
    "            with open(label_path, 'w') as f:\n",
    "                for ann in annots_per_image.get(image_id, []):\n",
    "                    class_id = ann['category_id']\n",
    "                    x, y, w, h = ann['bbox']\n",
    "                    x_center = (x + w / 2) / width\n",
    "                    y_center = (y + h / 2) / height\n",
    "                    w /= width\n",
    "                    h /= height\n",
    "                    f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        write_labels_and_copy_images(\n",
    "            split_ids[split],\n",
    "            yolo_img_dirs[split],\n",
    "            yolo_lbl_dirs[split]\n",
    "        )\n",
    "\n",
    "    print(f\"YOLO conversion complete: {yolo_root}\")\n",
    "    print(f\"  Train: {len(split_ids['train'])}, Val: {len(split_ids['val'])}, Test: {len(split_ids['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0a9b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO conversion complete: ..\\data\\mju_waste_yolo_2475_renametest\n",
      "  Train: 1980, Val: 247, Test: 248\n"
     ]
    }
   ],
   "source": [
    "convert_coco_to_yolo(\n",
    "    coco_root= Path(\"..\") / \"data\" / \"mju-COCO\",\n",
    "    dataset_name=\"mju_waste\",\n",
    "    train_split=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfd2d884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved annotated image to: ..\\tests\\mju_waste_000318.jpg\n",
      "✅ Saved annotated image to: ..\\tests\\mju_waste_001865.jpg\n",
      "✅ Saved annotated image to: ..\\tests\\mju_waste_001453.jpg\n"
     ]
    }
   ],
   "source": [
    "## plot the annotated images to check the yolo bounding boxes\n",
    "# set paths\n",
    "\n",
    "dataset_dir = Path(\"..\") / \"data\" / \"mju_waste_yolo_2475_renametest\" \n",
    "images_dir = dataset_dir / \"images\" / \"train\"\n",
    "labels_dir = dataset_dir / \"labels\" / \"train\"\n",
    "output_dir = Path(\"..\") / \"tests\" \n",
    "class_names = [\"trash\"]\n",
    "\n",
    "# Get all image paths and sample 3 random images\n",
    "image_paths = list(images_dir.glob(\"*.jpg\"))\n",
    "random_images = random.sample(image_paths, min(3, len(image_paths)))\n",
    "\n",
    "for image_path in random_images:\n",
    "    label_path = labels_dir / (image_path.stem + \".txt\")\n",
    "\n",
    "    # Read image\n",
    "    image = cv2.imread(str(image_path))\n",
    "    if image is None:\n",
    "        print(f\"Could not load image: {image_path}\")\n",
    "        continue\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # Read and draw bounding boxes\n",
    "    if label_path.exists():\n",
    "        with label_path.open(\"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    continue\n",
    "\n",
    "                cls, x_center, y_center, box_w, box_h = map(float, parts)\n",
    "                x_center *= w\n",
    "                y_center *= h\n",
    "                box_w *= w\n",
    "                box_h *= h\n",
    "\n",
    "                x1 = int(x_center - box_w / 2)\n",
    "                y1 = int(y_center - box_h / 2)\n",
    "                x2 = int(x_center + box_w / 2)\n",
    "                y2 = int(y_center + box_h / 2)\n",
    "\n",
    "                # Draw bounding box and class label\n",
    "                label = class_names[int(cls)] if int(cls) < len(class_names) else str(int(cls))\n",
    "                cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(image, label, (x1, y1 - 8), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.6, (0, 255, 0), 2)\n",
    "    else:\n",
    "        print(f\"No label found for {image_path.name}\")\n",
    "\n",
    "    # Show image\n",
    "    output_path = output_dir / image_path.name\n",
    "    cv2.imwrite(str(output_path), image)\n",
    "    print(f\"✅ Saved annotated image to: {output_path}\")\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CUDA_py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
