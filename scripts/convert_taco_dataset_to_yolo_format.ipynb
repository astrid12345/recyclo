{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNXR98QXEBEdFPwC4DWfxHA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astrid12345/recyclo/blob/convert_taco_to_yolo/scripts/convert_taco_dataset_to_yolo_format.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this notebook is to convert a COCO-ish dataset to a format that can be used to train an Ultralytics YOLO model.\n",
        "\n",
        "# Using this notebook: workflow\n",
        "\n",
        "To use, make a copy of this notebook, and adapt it to work with your specific dataset. Please save your version of this ipynb file on GitHub in *recyclo/scripts*.\n",
        "\n",
        "(File > Save a copy in GitHub > File path = \"scripts/my_filename.ipynb\" to save notebook in scripts folder)\n",
        "\n",
        "Once you've generated your YOLO dataset, and are confident you can train a model with it, please upload your converted dataset to the Recyclo datasets google drive, https://drive.google.com/drive/folders/1bUkIYQRXX08OKI5TuOSg-eqntSudGaFB.\n",
        "\n",
        "(Why Google Drive? Because these datasets are too large for GitHub!)\n",
        "\n",
        "# What's in this notebook: contents\n",
        "\n",
        "Notebook contents:\n",
        "- intro to YOLO\n",
        "- intro to COCO\n",
        "- dataset specific notes (update for your specific dataset)\n",
        "- convert dataset to simple COCO (update for your specific dataset)\n",
        "- convert simple COCO to YOLO\n",
        "\n",
        "# Pro tips about Colabs\n",
        "\n",
        "When you open the \"Files\" tab on the left, you'll find yourself in a folder containing\n",
        "* ..\n",
        "* sample data\n",
        "\n",
        "This is a colab thing, the \"content\" folder, to get you started.\n",
        "Ignore it: click the .. to go up a level."
      ],
      "metadata": {
        "id": "WYhAfcih9-9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro to YOLO\n",
        "\n",
        "## General\n",
        "\n",
        "In general, YOLO models output the following for a given image:\n",
        "* Bounding box\n",
        "* Class label\n",
        "* Confidence score\n",
        "\n",
        "To train a YOLO model, we need object detection datasets that contain images of what we're looking for (trash), and annotations: class labels and bounding boxes.\n",
        "\n",
        "## Ultralytics YOLO\n",
        "\n",
        "In this project we will use Ultralytics YOLO object detection, eg their YOLO11n model. YOLO11n is a pretrained object detection model developed by Ultralytics.\n",
        "\n",
        "Ultralytics YOLO expects datasets in the following format:\n",
        "\n",
        "```\n",
        "dataset/\n",
        "├── images/\n",
        "│   ├── train/  <-- image files for training.\n",
        "│   ├── val/    <-- image files for validation after each epoch. Must not overlap with images in train.\n",
        "|   └── test/   <-- optional: can put some image files here for benchmarking.\n",
        "├── labels/\n",
        "│   ├── train/  <-- one .txt file per train image (must have same name). Contains class and bbox info..\n",
        "│   ├── val/    <-- one .txt file per val image.\n",
        "|   └── test/   <-- one .txt file per test image.\n",
        "└── data.yaml   <-- config file; helps tie all the above together.\n",
        "```\n",
        "\n",
        "Example labels/train file:\n",
        "```\n",
        "<class_id> <x_center> <y_center> <width> <height>\n",
        "```\n",
        "\n",
        "Example data.yaml file:\n",
        "```\n",
        "path: /content/dataset  # Root folder\n",
        "train: images/train\n",
        "val: images/val\n",
        "\n",
        "nc: 5  # number of classes\n",
        "names: ['bottle', 'can', 'plastic bag', 'wrapper', 'paper']\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "x347PAo8rkYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro to COCO\n",
        "\n",
        "## General\n",
        "COCO, Common Objects in Context, is a object detection, segmentation, and captioning dataset developed by Microsoft. It uses an annotations.json file to organize image data. This json annotation approach has become standard for other datasets to use.\n",
        "\n",
        "Lots of datasets use COCO-style of formatting. In addition to the training images themselves, these datasets have at least one annotations json file which contains the following:\n",
        "*   \"images\":  List of image metadata\n",
        "*   \"annotations\":  List of label data (type of trash, bounding box definition, segmentation data; corresponds to images list)\n",
        "*   \"categories\":  List of the different categories this dataset uses\n",
        "\n",
        "An example of a COCO-style dataset file structure is as follows:\n",
        "```\n",
        "dataset/\n",
        "├── annotations/\n",
        "│   ├── instances_train2017.json\n",
        "│   ├── instances_val2017.json\n",
        "│   ├── person_keypoints_train2017.json\n",
        "│   ├── captions_train2017.json\n",
        "│   └── ... (other task-specific .json files)\n",
        "├── images/\n",
        "│   ├── train2017/\n",
        "│   │   ├── 000000000009.jpg\n",
        "│   │   ├── 000000000025.jpg\n",
        "│   │   └── ...\n",
        "│   └── val2017/\n",
        "│       ├── 000000000139.jpg\n",
        "│       ├── 000000000285.jpg\n",
        "│       └── ...\n",
        "└── LICENSE.txt (optional)\n",
        "```\n",
        "\n",
        "## Simple COCO format required by the COCO-to-YOLO conversion function\n",
        "\n",
        "\n",
        "To use the COCO to YOLO conversion function below, your data set must conform to the following (vastly simplified) COCO-like directory structure and json structure. It's unlikely that your dataset will conform to these specifications out of the box, so please use the code section below to modify your data's structure to match.\n",
        "\n",
        "The simple COCO directory structure must be as follows, with a folder called \"dataset\" located in your \"content\" directory:\n",
        "```\n",
        "dataset/\n",
        "├── images/\n",
        "│   ├── 000001.jpg  # or png or whatever\n",
        "│   ├── 000002.jpg\n",
        "│   └── ...\n",
        "└── annotations.json\n",
        "```\n",
        "\n",
        "And the annotations.json file must contain information in the following structure, and using the following json keywords:\n",
        "```\n",
        "{\n",
        "  \"images\": [\n",
        "    {\n",
        "      \"id\": 1,\n",
        "      \"file_name\": \"000001.jpg\",\n",
        "      \"width\": 640,\n",
        "      \"height\": 480\n",
        "    },\n",
        "    {\n",
        "      \"id\": 2,\n",
        "      \"file_name\": \"000002.jpg\",\n",
        "      \"width\": 800,\n",
        "      \"height\": 600\n",
        "    }\n",
        "  ],\n",
        "  \"annotations\": [\n",
        "    {\n",
        "      \"id\": 1,\n",
        "      \"image_id\": 1,\n",
        "      \"category_id\": 1,\n",
        "      \"bbox\": [100, 120, 50, 60],\n",
        "      \"area\": 3000,\n",
        "      \"iscrowd\": 0\n",
        "    },\n",
        "    {\n",
        "      \"id\": 2,\n",
        "      \"image_id\": 2,\n",
        "      \"category_id\": 2,\n",
        "      \"bbox\": [20, 30, 40, 50],\n",
        "      \"area\": 2000,\n",
        "      \"iscrowd\": 0\n",
        "    }\n",
        "  ],\n",
        "  \"categories\": [\n",
        "    {\n",
        "      \"id\": 1,\n",
        "      \"name\": \"plastic\"\n",
        "    },\n",
        "    {\n",
        "      \"id\": 2,\n",
        "      \"name\": \"metal\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n"
      ],
      "metadata": {
        "id": "wKqkU54arQMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helpful functions\n",
        "\n",
        "This section has some helpful functions you can use later in this notebook."
      ],
      "metadata": {
        "id": "epBrA9Nccr7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ⚠️ DO NOT MODIFY THIS CELL\n",
        "# This cell sets up a helpful function for inspecting json file contents\n",
        "\n",
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "def show_first_two_per_category(json_path):\n",
        "    \"\"\"\n",
        "    Prints the first two entries of each root-level list in a JSON file.\n",
        "\n",
        "    Useful for quickly inspecting the structure and content of a COCO-style\n",
        "    annotations json file.\n",
        "\n",
        "    It pretty-prints the first two entries of each top-level key that contains a list.\n",
        "\n",
        "    Args:\n",
        "        json_path (str or Path): Path to the JSON file to inspect.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the provided path does not point to an existing file.\n",
        "        json.JSONDecodeError: If the file is not valid JSON.\n",
        "    \"\"\"\n",
        "    json_path = Path(json_path)\n",
        "\n",
        "    if not json_path.exists():\n",
        "        print(f\"File not found: {json_path}\")\n",
        "        return\n",
        "\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    for key, value in data.items():\n",
        "        print(f\"\\n--- {key.upper()} (showing first 2 entries) ---\")\n",
        "        if isinstance(value, list):\n",
        "            for item in value[:2]:\n",
        "                pprint(item)\n",
        "        else:\n",
        "            print(f\"{key} is not a list, skipping.\")"
      ],
      "metadata": {
        "id": "CgZ9lFw7bpLv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "⚠️‼️ ***THE SECTION TO CHANGE FOR YOUR SPECIFIC DATASET STARTS HERE*** ‼️⚠️\n",
        "\n",
        "The sections above apply for all dataset conversions.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "GUP0h7VX_seR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✏️ Enter your dataset-specific code here\n",
        "# This cell is for importing your dataset to the notebook, and defining its name and path.\n",
        "\n",
        "# TACO: Sometimes you have to wait a while or run this twice for it to show up in the file tree\n",
        "import kagglehub\n",
        "from pathlib import Path\n",
        "\n",
        "dataset_name = \"TACO\"\n",
        "taco_dataset_path = Path(kagglehub.dataset_download('kneroma/tacotrashdataset'))  # https://www.kaggle.com/datasets/kneroma/tacotrashdataset\n",
        "\n",
        "print(f\"{dataset_name} dataset downloaded to {taco_dataset_path}\\n\")"
      ],
      "metadata": {
        "id": "DwT18ruVap0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✏️ Enter your dataset-specific code here\n",
        "# This cell is for inspecting your annotations json file(s), to help discover some of the quirks your dataset has\n",
        "\n",
        "show_first_two_per_category(taco_dataset_path / \"data\" / \"annotations.json\")"
      ],
      "metadata": {
        "id": "r4jKmumvccnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TACO dataset\n",
        "✏️ Modify this section for your specific dataset.\n",
        "\n",
        "The TACO dataset uses COCO-style formatting (it has segmentation).\n",
        "\n",
        "## Quirks\n",
        "\n",
        "TACO has 15 batch folders, each containing jpgs with names like 000000.jpg, 000001.jpg, 000002.jpg, etc.\n",
        "* Some numbers are skipped, eg 000000.jpg, 000001.jpg, 000003.jpg.\n",
        "* The name 000000.jpg is used in multiple batch folders, to name different image files.\n",
        "* It contains segmentation data (will be discarded).\n",
        "* It uses categories (specific) and supercategories (more general) - only the supercategories will be retained.\n",
        "* It includes scene categories (eg clearn streets) - this will be discarded.\n",
        "  * It might be interesting in the future to consider using a multi-tasking model - detecting trash and also classsifying the scene might improve the models performance by adding a bit of context awareness.\n",
        "\n",
        "## Conversion\n",
        "To convert the TACO dataset to a format ultralytics YOLO can use, we must:\n",
        "* Give the images unique names\n",
        "* Split the TACO images into train and val sets\n",
        "* Extract label and bbox info from annotations.json, and save it in individual txt files corresponding to the image files\n",
        "* Make a data.yaml file"
      ],
      "metadata": {
        "id": "f7u6PWyfxeLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✏️ Enter your dataset-specific code here\n",
        "# This cell is for modifying your dataset structure to match the required simple COCO style\n",
        "\n",
        "import shutil\n",
        "\n",
        "source_root = taco_dataset_path / \"data\"\n",
        "annotations_path = source_root / 'annotations.json'\n",
        "\n",
        "target_root = Path('/content/dataset')\n",
        "target_img_dir = target_root / 'images'\n",
        "if target_root.exists():\n",
        "    shutil.rmtree(target_root)\n",
        "target_img_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with annotations_path.open('r') as f:\n",
        "    annotations = json.load(f)\n",
        "\n",
        "# Reassign file names with unique zero-padded numbering\n",
        "image_id_map = {}\n",
        "for idx, image_info in enumerate(annotations['images']):\n",
        "    old_path = source_root / image_info['file_name']\n",
        "    new_filename = f\"{idx:06}.jpg\"\n",
        "    new_path = target_img_dir / new_filename\n",
        "\n",
        "    image_id_map[old_path] = new_path\n",
        "    image_info['file_name'] = new_filename\n",
        "\n",
        "    # Keep only required image fields\n",
        "    annotations['images'][idx] = {\n",
        "        'id': image_info['id'],\n",
        "        'file_name': new_filename,\n",
        "        'width': image_info['width'],\n",
        "        'height': image_info['height']\n",
        "    }\n",
        "\n",
        "# Prune annotation fields\n",
        "for ann in annotations['annotations']:\n",
        "    ann_keys = ['id', 'image_id', 'category_id', 'bbox', 'area', 'iscrowd']\n",
        "    for key in list(ann.keys()):\n",
        "        if key not in ann_keys:\n",
        "            del ann[key]\n",
        "\n",
        "# Update category entries to only include id and name = supercategory\n",
        "for cat in annotations['categories']:\n",
        "    cat_keys = ['id', 'name']\n",
        "    for key in list(cat.keys()):\n",
        "        if key not in cat_keys:\n",
        "            del cat[key]\n",
        "\n",
        "# Copy image files to new location\n",
        "for src, dst in image_id_map.items():\n",
        "    if src.exists():\n",
        "        shutil.copy(src, dst)\n",
        "    else:\n",
        "        print(f\"Warning: Missing image: {src}\")\n",
        "\n",
        "# Remove unwanted top-level keys\n",
        "for key in ['info', 'scene_annotations', 'scene_categories', 'licenses']:\n",
        "    annotations.pop(key, None)\n",
        "\n",
        "# Save cleaned annotations\n",
        "new_annotations_path = target_root / 'annotations.json'\n",
        "with new_annotations_path.open('w') as f:\n",
        "    json.dump(annotations, f)\n",
        "\n",
        "print(f\"Converted and cleaned {len(image_id_map)} images.\")"
      ],
      "metadata": {
        "id": "Usb6nID5YC8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "⚠️‼️ ***THE SECTION TO CHANGE FOR YOUR SPECIFIC DATASET STOPS HERE*** ‼️⚠️\n",
        "\n",
        "The sections below apply for all dataset conversions.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "osDjmxq9FhmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ⚠️ DO NOT MODIFY THIS CELL\n",
        "# This cell shows part of your annotations.json file to make sure the format and field names match the required simple COCO format\n",
        "\n",
        "show_first_two_per_category(target_root / \"annotations.json\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EB3t3Ey-hq9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ⚠️ DO NOT MODIFY THIS CELL\n",
        "# This cell sets up the function that converts the simple COCO dataset to YOLO format\n",
        "\n",
        "import shutil\n",
        "import random\n",
        "import yaml\n",
        "from collections import defaultdict\n",
        "\n",
        "def convert_coco_to_yolo(coco_root: Path, dataset_name: str, train_split: float = 0.8):\n",
        "    \"\"\"\n",
        "    Converts a simple COCO dataset to YOLOv8 format, including train/val split and data.yaml generation.\n",
        "\n",
        "    Args:\n",
        "        coco_root (Path): Path to the root of the simple COCO dataset (should contain images/ and annotations.json).\n",
        "        dataset_name (str): Name of the output dataset folder (e.g., \"taco\" -> creates \"taco_yolo\").\n",
        "        train_split (float, optional): Fraction of images to use for training. Defaults to 0.8.\n",
        "          The remaining images are split between validation and testing.\n",
        "\n",
        "    Returns:\n",
        "        Path: Path to the data.yaml file\n",
        "    \"\"\"\n",
        "    # Paths\n",
        "    coco_json_path = coco_root / 'annotations.json'\n",
        "    coco_images_path = coco_root / 'images'\n",
        "\n",
        "    # Load COCO JSON and get number of images for naming\n",
        "    with open(coco_json_path, 'r') as f:\n",
        "        coco = json.load(f)\n",
        "    n_total = len(coco['images'])\n",
        "\n",
        "    # Paths con't\n",
        "    yolo_root = coco_root.parent / f\"{dataset_name}_yolo_{n_total}\"\n",
        "    yolo_img_dirs = {\n",
        "        'train': yolo_root / 'images' / 'train',\n",
        "        'val': yolo_root / 'images' / 'val',\n",
        "        'test': yolo_root / 'images' / 'test',\n",
        "    }\n",
        "    yolo_lbl_dirs = {\n",
        "        'train': yolo_root / 'labels' / 'train',\n",
        "        'val': yolo_root / 'labels' / 'val',\n",
        "        'test': yolo_root / 'labels' / 'test',\n",
        "    }\n",
        "\n",
        "    # Clear and recreate folders\n",
        "    for d in list(yolo_img_dirs.values()) + list(yolo_lbl_dirs.values()):\n",
        "        if d.exists():\n",
        "            shutil.rmtree(d)\n",
        "        d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Map image_id -> metadata\n",
        "    image_info = {img['id']: (img['width'], img['height'], img['file_name']) for img in coco['images']}\n",
        "\n",
        "    # Map image_id -> annotations\n",
        "    annots_per_image = defaultdict(list)\n",
        "    for ann in coco['annotations']:\n",
        "        annots_per_image[ann['image_id']].append(ann)\n",
        "\n",
        "    # Shuffle and split image IDs\n",
        "    all_image_ids = list(image_info.keys())\n",
        "    random.shuffle(all_image_ids)\n",
        "    n_total = len(all_image_ids)\n",
        "    n_train = int(n_total * train_split)\n",
        "    n_val = int((n_total - n_train) / 2)\n",
        "    n_test = n_total - n_train - n_val\n",
        "\n",
        "    split_ids = {\n",
        "        'train': set(all_image_ids[:n_train]),\n",
        "        'val': set(all_image_ids[n_train:n_train + n_val]),\n",
        "        'test': set(all_image_ids[n_train + n_val:]),\n",
        "    }\n",
        "\n",
        "    def write_labels_and_copy_images(image_ids, img_dir, lbl_dir):\n",
        "        for image_id in image_ids:\n",
        "            width, height, filename = image_info[image_id]\n",
        "            orig_stem = Path(filename).stem\n",
        "            new_stem = f\"{dataset_name}_{orig_stem}\"\n",
        "            label_path = lbl_dir / f\"{new_stem}.txt\"\n",
        "            image_src = coco_images_path / filename\n",
        "            image_dst = img_dir / f\"{new_stem}.jpg\"\n",
        "\n",
        "            # Copy image\n",
        "            if image_src.exists():\n",
        "                shutil.copy(image_src, image_dst)\n",
        "            else:\n",
        "                print(f\"Warning: Image not found: {image_src}\")\n",
        "                continue\n",
        "\n",
        "            # Write labels\n",
        "            with open(label_path, 'w') as f:\n",
        "                for ann in annots_per_image.get(image_id, []):\n",
        "                    class_id = ann['category_id']\n",
        "                    x, y, w, h = ann['bbox']\n",
        "                    x_center = (x + w / 2) / width\n",
        "                    y_center = (y + h / 2) / height\n",
        "                    w /= width\n",
        "                    h /= height\n",
        "                    f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\\n\")\n",
        "\n",
        "    # Process splits\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        write_labels_and_copy_images(\n",
        "            split_ids[split],\n",
        "            yolo_img_dirs[split],\n",
        "            yolo_lbl_dirs[split]\n",
        "        )\n",
        "\n",
        "    # Build data.yaml\n",
        "    categories = sorted(coco['categories'], key=lambda x: x['id'])\n",
        "    names = [cat['name'] for cat in categories]\n",
        "    data_yaml = {\n",
        "        'path': str(yolo_root),\n",
        "        'train': 'images/train',\n",
        "        'val': 'images/val',\n",
        "        'test': 'images/test',\n",
        "        'nc': len(names),\n",
        "        'names': names\n",
        "    }\n",
        "\n",
        "    with open(yolo_root / 'data.yaml', 'w') as f:\n",
        "        yaml.dump(data_yaml, f)\n",
        "\n",
        "    print(f\"YOLO conversion complete: {yolo_root}\")\n",
        "    print(f\"  Train: {len(split_ids['train'])}, Val: {len(split_ids['val'])}, Test: {len(split_ids['test'])}\")\n",
        "    return yolo_root / 'data.yaml'"
      ],
      "metadata": {
        "id": "w0VITl3VnG_n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ⚠️ DO NOT MODIFY THIS CELL\n",
        "# This cell executes the simple COCO dataset to YOLO conversion\n",
        "\n",
        "yolo_data = convert_coco_to_yolo(target_root, dataset_name)"
      ],
      "metadata": {
        "id": "L_uawwBmoB2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To verify that your conversion worked, make sure you can train a model and that it outputs images with a bounding box and label."
      ],
      "metadata": {
        "id": "xpsMcME2-rDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ⚠️ DO NOT MODIFY THIS CELL\n",
        "# This cell imports the ultralytics library required for training a model\n",
        "\n",
        "!pip install -U ultralytics\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import os"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Mb5g0TegvNCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ⚠️ DO NOT MODIFY THIS CELL\n",
        "# This cell trains a YOLO model on the converted YOLO dataset to see if it's set up correctly\n",
        "# Tip: inspect the output of this cell to assess whether training occured properly.\n",
        "\n",
        "model = YOLO('yolo11n.pt')\n",
        "results = model.train(data=str(yolo_data), epochs=4, imgsz=640)  # epoch size is small - this is just to see if it can work!"
      ],
      "metadata": {
        "collapsed": true,
        "id": "UL4rIlXU-oLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the model outputs even one image with a bounding box and label, then the dataset should work for our project! Verify this using the code below."
      ],
      "metadata": {
        "id": "2JPNfPNAEtFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ⚠️ DO NOT MODIFY THIS CELL\n",
        "# This cell passes the trained model some images, to see if the model can identify some trash\n",
        "\n",
        "import cv2\n",
        "from random import sample\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the latest model\n",
        "runs_detect_dir = Path('runs/detect')\n",
        "train_dirs = [d for d in runs_detect_dir.iterdir() if d.is_dir() and d.name.startswith(\"train\")]\n",
        "train_dirs.sort(key=lambda d: d.stat().st_mtime, reverse=True)  # sort by modification time\n",
        "latest_train_dir = train_dirs[0]\n",
        "best_model_path = latest_train_dir / 'weights' / 'best.pt'\n",
        "print(f\"Loading {best_model_path}\")\n",
        "\n",
        "# Load the model and try it out\n",
        "model = YOLO(best_model_path)\n",
        "train_images_path = yolo_data.parent / \"images\" / \"train\"\n",
        "image_files = list(train_images_path.glob('*.jpg'))\n",
        "\n",
        "sample_images = sample(image_files, 10)\n",
        "\n",
        "for image_path in sample_images:\n",
        "    result = model(image_path)[0]\n",
        "    annotated_image = result.plot()\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(annotated_image)\n",
        "    plt.title(f'Predictions: {image_path.name}')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Apy8pfX6Eyhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the model successfully generated even one image with a bounding box and label, please run the following code block to zip the taco_yolo dataset, download the zipped file, and upload it on Google Drive, https://www.google.com/url?q=https%3A%2F%2Fdrive.google.com%2Fdrive%2Ffolders%2F1bUkIYQRXX08OKI5TuOSg-eqntSudGaFB."
      ],
      "metadata": {
        "id": "zj5c-mtlL2gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ⚠️ DO NOT MODIFY THIS CELL\n",
        "# This cell zips your converted YOLO dataset with an informative name, so you can download it and upload it to google drive.\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "# Generate date prefix\n",
        "date_str = datetime.now().strftime('%Y%m%d')\n",
        "zip_name = f\"{date_str}_{yolo_data.parent.stem}.zip\"\n",
        "\n",
        "# Change directory and zip\n",
        "%cd {yolo_data.parent}\n",
        "!zip -r /content/{zip_name} .\n",
        "\n",
        "print(f\"Zip created at /content/{zip_name}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ik8EKrBMLyap"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}