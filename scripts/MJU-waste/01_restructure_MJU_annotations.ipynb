{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55ca0986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.146  Python-3.11.9 torch-2.6.0+cu118 CUDA:0 (GeForce GTX 1650, 4096MiB)\n",
      "Setup complete  (12 CPUs, 15.9 GB RAM, 150.7/931.5 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from pprint import pprint\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad53ec0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a80c0bb",
   "metadata": {},
   "source": [
    "Only run this notebook once, after downloading the dataset!\n",
    "\n",
    "It inspects the labels and annotations, cleans up the COCO annotation json, corrects the bbox and stores results in clean_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98b58b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get COCO formatted data: \n",
    "# download the dataset from https://datasetninja.com/mju-waste#download and place in folder 'data/mju-waste-COCO\n",
    "# clone the instances.json files from https://github.com/realwecan/mju-waste and place in folder 'data/mju-waste-COCO/annotations'\n",
    "\n",
    "#! ⚠️ IMPORTANT: bbox is NOT in the right location, we will construct it ourselves from the segmentation coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe384a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- INFO (showing first 2 entries) ---\n",
      "info is not a list, skipping.\n",
      "\n",
      "--- LICENSES (showing first 2 entries) ---\n",
      "licenses is not a list, skipping.\n",
      "\n",
      "--- CATEGORIES (showing first 2 entries) ---\n",
      "{'id': 0, 'name': 'Rubbish', 'supercategory': 'Waste'}\n",
      "\n",
      "--- ANNOTATIONS (showing first 2 entries) ---\n",
      "{'area': 11013.695949999998,\n",
      " 'bbox': [450, 255, 137, 204],\n",
      " 'category_id': 0,\n",
      " 'id': 1621,\n",
      " 'image_id': 1617,\n",
      " 'iscrowd': 0,\n",
      " 'segmentation': [318.11,\n",
      "                  188.75,\n",
      "                  332.25,\n",
      "                  324.48,\n",
      "                  414.96,\n",
      "                  315.99,\n",
      "                  395.17,\n",
      "                  180.27,\n",
      "                  318.11,\n",
      "                  188.04]}\n",
      "{'area': 13896.986949999991,\n",
      " 'bbox': [403, 228, 149, 198],\n",
      " 'category_id': 0,\n",
      " 'id': 1622,\n",
      " 'image_id': 1618,\n",
      " 'iscrowd': 0,\n",
      " 'segmentation': [287.01,\n",
      "                  164.71,\n",
      "                  385.98,\n",
      "                  162.59,\n",
      "                  390.22,\n",
      "                  296.2,\n",
      "                  285.6,\n",
      "                  301.15,\n",
      "                  284.89,\n",
      "                  161.18]}\n",
      "\n",
      "--- IMAGES (showing first 2 entries) ---\n",
      "{'coco_url': '',\n",
      " 'date_captured': '2019-11-21 16:19:37',\n",
      " 'file_name': '2019-09-19_16_19_32-29_color.png',\n",
      " 'flickr_url': '',\n",
      " 'height': 480,\n",
      " 'id': 1617,\n",
      " 'license': 1,\n",
      " 'width': 640}\n",
      "{'coco_url': '',\n",
      " 'date_captured': '2019-11-21 16:19:37',\n",
      " 'file_name': '2019-09-19_16_19_44-93_color.png',\n",
      " 'flickr_url': '',\n",
      " 'height': 480,\n",
      " 'id': 1618,\n",
      " 'license': 1,\n",
      " 'width': 640}\n"
     ]
    }
   ],
   "source": [
    "# inspect annotations file\n",
    "def show_first_two_per_category(json_path):\n",
    "    \"\"\"\n",
    "    Prints the first two entries of each root-level list in a JSON file.\n",
    "\n",
    "    Useful for quickly inspecting the structure and content of a COCO-style\n",
    "    annotations json file.\n",
    "\n",
    "    It pretty-prints the first two entries of each top-level key that contains a list.\n",
    "\n",
    "    Args:\n",
    "        json_path (str or Path): Path to the JSON file to inspect.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the provided path does not point to an existing file.\n",
    "        json.JSONDecodeError: If the file is not valid JSON.\n",
    "    \"\"\"\n",
    "    json_path = Path(json_path)\n",
    "\n",
    "    if not json_path.exists():\n",
    "        print(f\"File not found: {json_path}\")\n",
    "        return\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for key, value in data.items():\n",
    "        print(f\"\\n--- {key.upper()} (showing first 2 entries) ---\")\n",
    "        if isinstance(value, list):\n",
    "            for item in value[:2]:\n",
    "                pprint(item)\n",
    "        else:\n",
    "            print(f\"{key} is not a list, skipping.\")\n",
    "\n",
    "\n",
    "show_first_two_per_category(json_path=Path(\"../..\") / \"data\" / \"mju-waste-COCO\" / \"annotations\" / \"train.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15141903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined cleaned annotations to ..\\..\\data\\mju-waste-COCO\\clean_annotations\\annotations.json\n",
      "Total images: 2475\n",
      "Total annotations: 2532\n"
     ]
    }
   ],
   "source": [
    "# Combines the train, val, and test JSON files from the MJU Waste dataset into a single COCO-style JSON file.\n",
    "# it also cleans the annotation files, \n",
    "# only keeping annotation id, image_id, category_id (set to 0 for 'trash'), area, and iscrowd.\n",
    "# ⚠️IMPORTANT: this cell computes the bounding box from the segmentation coordinates\n",
    "\n",
    "# Set paths\n",
    "input_dir = Path(\"../..\") / \"data\" / \"mju-waste-COCO\" / \"annotations\"\n",
    "output_file = Path(\"../..\") / \"data\" / \"mju-waste-COCO\" / \"clean_annotations\" / \"annotations.json\"\n",
    "output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Files to process\n",
    "splits = ['train', 'val', 'test']\n",
    "\n",
    "combined_images = []\n",
    "combined_annotations = []\n",
    "annotation_id = 0\n",
    "image_ids_seen = set()\n",
    "\n",
    "for split in splits:\n",
    "    input_file = input_dir / f\"{split}.json\"\n",
    "\n",
    "    with input_file.open('r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for img in data.get(\"images\", []):\n",
    "        if img[\"id\"] not in image_ids_seen:\n",
    "            combined_images.append(img)\n",
    "            image_ids_seen.add(img[\"id\"])\n",
    "\n",
    "    for ann in data.get(\"annotations\", []):\n",
    "        # compute bbox from segmentation\n",
    "        seg = ann['segmentation'] # input is flat list\n",
    "        # take all x coordinates\n",
    "        xs = seg[0::2]\n",
    "        # take all y coordinates from segmentation\n",
    "        ys = seg[1::2]\n",
    "        # find the bouding boxes\n",
    "        x_min = min(xs)\n",
    "        y_min = min(ys)\n",
    "        x_max = max(xs)\n",
    "        y_max = max(ys)\n",
    "        # calculate width and height of the bounding box\n",
    "        width = round(x_max - x_min, 2)\n",
    "        height = round(y_max - y_min, 2)\n",
    "\n",
    "        cleaned_ann = {\n",
    "            'id': annotation_id,\n",
    "            'image_id': ann['image_id'],\n",
    "            'category_id': 0,  # unify to 'trash'\n",
    "            'segmentation': ann['segmentation'],\n",
    "            'area': ann['area'],\n",
    "            'iscrowd': ann.get('iscrowd', 0),\n",
    "            # add my own bbox from segmentation\n",
    "            'bbox': [x_min, y_min, width, height]\n",
    "\n",
    "        }\n",
    "        combined_annotations.append(cleaned_ann)\n",
    "        annotation_id += 1\n",
    "\n",
    "# Set single category at the end\n",
    "categories = [{\"id\": 0, \"name\": \"trash\"}]\n",
    "\n",
    "# Build and save final dataset\n",
    "cleaned_data = {\n",
    "    'images': combined_images,\n",
    "    'annotations': combined_annotations,\n",
    "    'categories': categories\n",
    "}\n",
    "\n",
    "with output_file.open('w') as f:\n",
    "    json.dump(cleaned_data, f)\n",
    "\n",
    "print(f\"Saved combined cleaned annotations to {output_file}\")\n",
    "print(f\"Total images: {len(combined_images)}\")\n",
    "print(f\"Total annotations: {len(combined_annotations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc891908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All annotation image_ids are present in the image list.\n",
      "Annotations referencing missing images: 0\n"
     ]
    }
   ],
   "source": [
    "# Investigate mismatches between length of annotations and images\n",
    "image_ids_in_images = set(img[\"id\"] for img in combined_images)\n",
    "image_ids_in_annotations = set(ann[\"image_id\"] for ann in combined_annotations)\n",
    "\n",
    "# Check if all annotation image_ids exist in images\n",
    "missing_image_ids = image_ids_in_annotations - image_ids_in_images\n",
    "if missing_image_ids:\n",
    "    print(f\"⚠️ {len(missing_image_ids)} annotation image_ids are missing in images!\")\n",
    "    print(f\"Missing image_ids (up to 10 shown): {list(missing_image_ids)[:10]}\")\n",
    "    # Optionally, show counts of how many annotations reference each missing image_id\n",
    "    from collections import Counter\n",
    "    missing_counts = Counter([ann[\"image_id\"] for ann in combined_annotations if ann[\"image_id\"] in missing_image_ids])\n",
    "    print(f\"Counts of annotations per missing image_id (up to 5 shown): {missing_counts.most_common(5)}\")\n",
    "else:\n",
    "    print(\"✅ All annotation image_ids are present in the image list.\")\n",
    "\n",
    "# Optional: how many annotations reference missing images\n",
    "num_annotations_missing_image = sum(1 for ann in combined_annotations if ann[\"image_id\"] in missing_image_ids)\n",
    "print(f\"Annotations referencing missing images: {num_annotations_missing_image}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54ba663c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- IMAGES (showing first 2 entries) ---\n",
      "{'coco_url': '',\n",
      " 'date_captured': '2019-11-21 16:19:37',\n",
      " 'file_name': '2019-09-19_16_19_32-29_color.png',\n",
      " 'flickr_url': '',\n",
      " 'height': 480,\n",
      " 'id': 1617,\n",
      " 'license': 1,\n",
      " 'width': 640}\n",
      "{'coco_url': '',\n",
      " 'date_captured': '2019-11-21 16:19:37',\n",
      " 'file_name': '2019-09-19_16_19_44-93_color.png',\n",
      " 'flickr_url': '',\n",
      " 'height': 480,\n",
      " 'id': 1618,\n",
      " 'license': 1,\n",
      " 'width': 640}\n",
      "\n",
      "--- ANNOTATIONS (showing first 2 entries) ---\n",
      "{'area': 11013.695949999998,\n",
      " 'bbox': [318.11, 180.27, 96.85, 144.21],\n",
      " 'category_id': 0,\n",
      " 'id': 0,\n",
      " 'image_id': 1617,\n",
      " 'iscrowd': 0,\n",
      " 'segmentation': [318.11,\n",
      "                  188.75,\n",
      "                  332.25,\n",
      "                  324.48,\n",
      "                  414.96,\n",
      "                  315.99,\n",
      "                  395.17,\n",
      "                  180.27,\n",
      "                  318.11,\n",
      "                  188.04]}\n",
      "{'area': 13896.986949999991,\n",
      " 'bbox': [284.89, 161.18, 105.33, 139.97],\n",
      " 'category_id': 0,\n",
      " 'id': 1,\n",
      " 'image_id': 1618,\n",
      " 'iscrowd': 0,\n",
      " 'segmentation': [287.01,\n",
      "                  164.71,\n",
      "                  385.98,\n",
      "                  162.59,\n",
      "                  390.22,\n",
      "                  296.2,\n",
      "                  285.6,\n",
      "                  301.15,\n",
      "                  284.89,\n",
      "                  161.18]}\n",
      "\n",
      "--- CATEGORIES (showing first 2 entries) ---\n",
      "{'id': 0, 'name': 'trash'}\n"
     ]
    }
   ],
   "source": [
    "# inspect results\n",
    "show_first_two_per_category(Path(\"../..\") / \"data\" / \"mju-waste-COCO\" / \"clean_annotations\" / \"annotations.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CUDA_py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
