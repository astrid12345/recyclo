{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM1daALCs8p+Eukn201p0lx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# [Benchmarking ](https://docs.ultralytics.com/modes/benchmark)\n","\n","## Introduction\n","\n","Once your model is trained and validated, the next logical step is to evaluate its performance in various real-world scenarios. Benchmark mode in Ultralytics YOLO11 serves this purpose by providing a robust framework for assessing the speed and accuracy of your model across a range of export formats.\n","\n","## Why Is Benchmarking Crucial?\n","*   Informed Decisions: Gain insights into the trade-offs between speed and accuracy.\n","*   Resource Allocation: Understand how different export formats perform on different hardware.\n","*   Optimization: Learn which export format offers the best performance for your specific use case.\n","*   Cost Efficiency: Make more efficient use of hardware resources based on benchmark results.\n","\n","## Key Metrics in Benchmark Mode\n","*   mAP50-95: For object detection, segmentation, and pose estimation.\n","*   accuracy_top5: For image classification.\n","*   Inference Time: Time taken for each image in milliseconds.\n","\n","\n","Supported Export Formats\n","\n","*   ONNX: For optimal CPU performance\n","*   TensorRT: For maximal GPU efficiency\n","*   OpenVINO: For Intel hardware optimization\n","*   CoreML, TensorFlow SavedModel, and More: For diverse deployment needs.\n","\n","### Tip\n","*   Export to ONNX or OpenVINO for up to 3x CPU speedup.\n","*   Export to TensorRT for up to 5x GPU speedup."],"metadata":{"id":"wjCN7I0N0Z7l"}},{"cell_type":"markdown","source":["## Usage Examples\n","\n","```\n","from ultralytics.utils.benchmarks import benchmark\n","\n","# Benchmark on GPU\n","benchmark(model=\"yolo11n.pt\", data=\"coco8.yaml\", imgsz=640, half=False, device=0)\n","\n","# Benchmark specific export format\n","benchmark(model=\"yolo11n.pt\", data=\"coco8.yaml\", imgsz=640, format=\"onnx\")\n","```\n","\n"],"metadata":{"id":"RR3k9Hnz2TzY"}},{"cell_type":"markdown","source":["## Arguments"],"metadata":{"id":"2oHFmnhk2guR"}},{"cell_type":"markdown","metadata":{"id":"b281350f"},"source":["| Key | Default Value | Description |\n","|---|---|---|\n","| model | None | Specifies the path to the model file. Accepts both .pt and .yaml formats, e.g., \"yolo11n.pt\" for pre-trained models or configuration files. |\n","| data | None | Path to a YAML file defining the dataset for benchmarking, typically including paths and settings for validation data. Example: \"coco8.yaml\". |\n","| imgsz | 640 | The input image size for the model. Can be a single integer for square images or a tuple (width, height) for non-square, e.g., (640, 480). |\n","| half | False | Enables FP16 (half-precision) inference, reducing memory usage and possibly increasing speed on compatible hardware. Use half=True to enable. |\n","| int8 | False | Activates INT8 quantization for further optimized performance on supported devices, especially useful for edge devices. Set int8=True to use. |\n","| device | None | Defines the computation device(s) for benchmarking, such as \"cpu\" or \"cuda:0\". |\n","| verbose | False | Controls the level of detail in logging output. Set verbose=True for detailed logs. |\n","| format | '' | Benchmark the model on a single export format. i.e format=onnx |"]},{"cell_type":"markdown","source":["## Export Formats\n","\n","Benchmarks will attempt to run automatically on all possible [export formats](https://docs.ultralytics.com/modes/export/). Alternatively, you can run benchmarks for a specific format by using the format argument, which accepts any of the formats mentioned below.\n","\n","There is an issue with the ONNX format related code, so as a workaround, we have to specify a single format as workaround.\n","\n","Exporting YOLO11 models to [different formats](https://docs.ultralytics.com/modes/benchmark/#supported-export-formats) such as ONNX, TensorRT, and OpenVINO allows you to optimize performance based on your deployment environment. For instance:\n","\n","*   ONNX: Best for CPU performance. Provides up to 3x CPU speedup.\n","*   TensorRT: Ideal for GPU efficiency. Offers up to 5x GPU speedup.\n","*   OpenVINO: Specifically optimized for Intel hardware.\n","*   CoreML & TensorFlow: Useful for iOS and general ML applications.\n","These formats enhance both the speed and accuracy of your models, making them more efficient for various real-world applications.\n"],"metadata":{"id":"WYLqeSWA34EN"}},{"cell_type":"code","source":["# ⚠️ NOTE THAT THERE IS AN ISSUE WITH THE GENERAL BENCHMARK METHOD\n","# We can specify a particular export format as a workaround. TensorRT(engine) is chosen here.\n","\n","from ultralytics.utils.benchmarks import benchmark\n","\n","# Choose a relevant model\n","model = YOLO(\"/content/runs/detect/train2/weights/best.pt\")\n","\n","results = model.benchmark(data=\"/content/AquaTrash_yolo_369/data.yaml\", imgsz=640, half=False, format=\"engine\")"],"metadata":{"id":"E4tsGaqEMxS2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# [Data Augmentation ](https://docs.ultralytics.com/guides/yolo-data-augmentation)\n","\n","## Introduction\n","Data augmentation is a crucial technique in computer vision that artificially expands your training dataset by applying various transformations to existing images. When training deep learning models like Ultralytics YOLO, data augmentation helps improve model robustness, reduces overfitting, and enhances generalization to real-world scenarios.\n","\n","## Why Data Augmentation Matters\n","\n","Data augmentation serves multiple critical purposes in training computer vision models:\n","\n","*   Expanded Dataset: By creating variations of existing images, you can effectively increase your training dataset size without collecting new data.\n","*   Improved Generalization: Models learn to recognize objects under various conditions, making them more robust in real-world applications.\n","*   Reduced Overfitting: By introducing variability in the training data, models are less likely to memorize specific image characteristics.\n","*   Enhanced Performance: Models trained with proper augmentation typically achieve better accuracy on validation and test sets.\n","\n","You can customize each parameter using the Python API, the command line interface (CLI), or a configuration file.\n","\n","### Python API\n","\n","```\n","from ultralytics import YOLO\n","\n","# Load a model\n","model = YOLO(\"yolo11n.pt\")\n","\n","# Training with custom augmentation parameters\n","model.train(data=\"coco.yaml\", epochs=100, hsv_h=0.03, hsv_s=0.6, hsv_v=0.5)\n","\n","# Training without any augmentations (disabled values omitted for clarity)\n","model.train(\n","    data=\"coco.yaml\",\n","    epochs=100,\n","    hsv_h=0.0, # Hue adjustment. Shifts image colors while preserving their relationships.\n","    hsv_s=0.0, # Saturation adjustment. Modifies the intensity of colors in the image.\n","    hsv_v=0.0, # Brightness adjustment. Changes the brightness of the image.\n","    degrees=45, # Rotation (0 - 180. 45 will result in rotation randomly selected between -45 to 45 deg.)\n","    translate=0.0, # Horizontal and vertical translation\n","    shear=0.0, # Introduces a geometric transformation that skews the image along both x-axis and y-axis.\n","    perspective=0.0, # Applies a full perspective transformation along both x-axis and y-axis, simulating how objects appear when viewed from different depths or angles.\n","    scale=0.0, # Resizes images by a random factor within the specified range.\n","    flipud=0.0, # Flip Up-Down\n","    fliplr=0.0, # Flip Left-Right\n","    bgr=0.0, # BGR Channel Swap\n","    mosaic=0.0, # Mosaic. Combines 4 training imgs into 1\n","    mixup=0.0, # Mixup. Combines 2 training imgs into 1\n","    erasing=0.0, # Randomly erases portions of the image during classification training.\n","    auto_augment=None, # Applies automated augmentation policies for classification.\n",")\n","```\n","\n","### Configuration File\n","You can define all training parameters, including augmentations, in a YAML configuration file (e.g., train_custom.yaml). The mode parameter is only required when using the CLI. This new YAML file will then override the default one located in the ultralytics package.\n","\n","```\n","# train_custom.yaml\n","# 'mode' is required only for CLI usage\n","mode: train\n","data: coco8.yaml\n","model: yolo11n.pt\n","epochs: 100\n","hsv_h: 0.03\n","hsv_s: 0.6\n","hsv_v: 0.5\n","```\n","Then launch the training with the Python API:\n","\n","\n","```\n","from ultralytics import YOLO\n","\n","# Load a COCO-pretrained YOLO11n model\n","model = YOLO(\"yolo11n.pt\")\n","\n","# Train the model with custom configuration\n","model.train(cfg=\"train_custom.yaml\")\n","```\n","\n","\n","\n","\n"],"metadata":{"id":"_3cPci7bJtm7"}},{"cell_type":"markdown","source":["The above does not cater for blur. To introduce blur, we need to install Albumentations packages. Once installed, when training with YOLO11, a set of augmentations is automatically applied through its integration with Albumentations, making it easy to enhance your model's performance.\n","\n","The augmentations includes operations such as Blur, Median Blur, conversion to grayscale, Contrast Limited Adaptive Histogram Equalization (CLAHE), random changes in brightness and contrast, RandomGamma, and image quality reduction through compression. Note that only the augmentations with a probability p greater than 0 are active. These are purposefully applied at low frequencies to mimic real-world visual artifacts, such as blur or grayscale effects.\n","\n","If the augmentations package is not installed, install using\n","`!pip install albumentations ultralytics`\n","\n"],"metadata":{"id":"GL78nmc4O1zx"}}]}